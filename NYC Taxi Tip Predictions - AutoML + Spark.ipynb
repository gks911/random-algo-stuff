{"cells":[{"cell_type":"markdown","source":["This notebook explores AutoML using Scalable Spark MLLib algorithms.\nThe data used in this notebook was obtained from http://www.andresmh.com/nyctaxitrips/.\n\n\n### Outline:\n1. Load Data\n2. Data Preparation and Analysis\n3. AutoML Experiment\n\n\n### Libraries:\n- Spark MLLib \n- Microsoft MMLSpark - https://github.com/Azure/mmlspark/blob/master/docs/lightgbm.md\n- MLFlow\n- AzureML - AutoML"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3781806-f26e-40f3-8c28-b93ccd2d4a3d"}}},{"cell_type":"markdown","source":["Broadly a machine learning experiment has three distinct steps - \n    1. Loading the dataset from a given source,\n    2. Doing some exploratory data analysis, to understand the data and the problem, and pre-processing it to make it ready for training a model\n    3. And then finally, training and evaluating a model\n\nThe third part is where AutoML helps users to automatically select a model that best fits the given data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fba962b1-0d05-48a2-9bcd-25d0056bc874"}}},{"cell_type":"markdown","source":["# 1. Loading Data\n\nThe entire NYC Taxi dataset is ~17GB in size, split across two tables each spanning multiple CSV files - one which contains information on the fares (e.g. total fare, tip amount etc.), and the other which contains information on the trips (e.g. pickup / dropoff location, trip duration etc.)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a339ee03-255b-4867-838d-99b30f1201ad"}}},{"cell_type":"code","source":["%fs ls dbfs:/databricks/datasets/nycfull"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f66c778-cd85-4cfe-84bc-d2fe48ef6d38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/databricks/datasets/nycfull/trip_data_1.csv","trip_data_1.csv",2459600863],["dbfs:/databricks/datasets/nycfull/trip_data_10.csv","trip_data_10.csv",2502278613],["dbfs:/databricks/datasets/nycfull/trip_data_11.csv","trip_data_11.csv",2395449056],["dbfs:/databricks/datasets/nycfull/trip_data_12.csv","trip_data_12.csv",2327237611],["dbfs:/databricks/datasets/nycfull/trip_data_2.csv","trip_data_2.csv",2328673265],["dbfs:/databricks/datasets/nycfull/trip_data_3.csv","trip_data_3.csv",2622301287],["dbfs:/databricks/datasets/nycfull/trip_data_4.csv","trip_data_4.csv",2515040578],["dbfs:/databricks/datasets/nycfull/trip_data_5.csv","trip_data_5.csv",2545680024],["dbfs:/databricks/datasets/nycfull/trip_data_6.csv","trip_data_6.csv",2396133818],["dbfs:/databricks/datasets/nycfull/trip_data_7.csv","trip_data_7.csv",2303297474],["dbfs:/databricks/datasets/nycfull/trip_data_8.csv","trip_data_8.csv",2100978620],["dbfs:/databricks/datasets/nycfull/trip_data_9.csv","trip_data_9.csv",2353003850],["dbfs:/databricks/datasets/nycfull/trip_fare_1.csv","trip_fare_1.csv",1681610043],["dbfs:/databricks/datasets/nycfull/trip_fare_10.csv","trip_fare_10.csv",1712562557],["dbfs:/databricks/datasets/nycfull/trip_fare_11.csv","trip_fare_11.csv",1641999933],["dbfs:/databricks/datasets/nycfull/trip_fare_12.csv","trip_fare_12.csv",1593879813],["dbfs:/databricks/datasets/nycfull/trip_fare_2.csv","trip_fare_2.csv",1593003695],["dbfs:/databricks/datasets/nycfull/trip_fare_3.csv","trip_fare_3.csv",1794836351],["dbfs:/databricks/datasets/nycfull/trip_fare_4.csv","trip_fare_4.csv",1721514415],["dbfs:/databricks/datasets/nycfull/trip_fare_5.csv","trip_fare_5.csv",1743431041],["dbfs:/databricks/datasets/nycfull/trip_fare_6.csv","trip_fare_6.csv",1641402184],["dbfs:/databricks/datasets/nycfull/trip_fare_7.csv","trip_fare_7.csv",1576268209],["dbfs:/databricks/datasets/nycfull/trip_fare_8.csv","trip_fare_8.csv",1436875197],["dbfs:/databricks/datasets/nycfull/trip_fare_9.csv","trip_fare_9.csv",1610146825]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_1.csv</td><td>trip_data_1.csv</td><td>2459600863</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_10.csv</td><td>trip_data_10.csv</td><td>2502278613</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_11.csv</td><td>trip_data_11.csv</td><td>2395449056</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_12.csv</td><td>trip_data_12.csv</td><td>2327237611</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_2.csv</td><td>trip_data_2.csv</td><td>2328673265</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_3.csv</td><td>trip_data_3.csv</td><td>2622301287</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_4.csv</td><td>trip_data_4.csv</td><td>2515040578</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_5.csv</td><td>trip_data_5.csv</td><td>2545680024</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_6.csv</td><td>trip_data_6.csv</td><td>2396133818</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_7.csv</td><td>trip_data_7.csv</td><td>2303297474</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_8.csv</td><td>trip_data_8.csv</td><td>2100978620</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_data_9.csv</td><td>trip_data_9.csv</td><td>2353003850</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_1.csv</td><td>trip_fare_1.csv</td><td>1681610043</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_10.csv</td><td>trip_fare_10.csv</td><td>1712562557</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_11.csv</td><td>trip_fare_11.csv</td><td>1641999933</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_12.csv</td><td>trip_fare_12.csv</td><td>1593879813</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_2.csv</td><td>trip_fare_2.csv</td><td>1593003695</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_3.csv</td><td>trip_fare_3.csv</td><td>1794836351</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_4.csv</td><td>trip_fare_4.csv</td><td>1721514415</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_5.csv</td><td>trip_fare_5.csv</td><td>1743431041</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_6.csv</td><td>trip_fare_6.csv</td><td>1641402184</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_7.csv</td><td>trip_fare_7.csv</td><td>1576268209</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_8.csv</td><td>trip_fare_8.csv</td><td>1436875197</td></tr><tr><td>dbfs:/databricks/datasets/nycfull/trip_fare_9.csv</td><td>trip_fare_9.csv</td><td>1610146825</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Loading using Pandas\nDue to the size of this dataset, we are inherently limited by the amount of memory we have on a single machine to load this dataset. The following cell outlines how we would load the NYC Taxi fares dataset using pandas, however it has been commented out due to the fact that we run into an out of memory (OOM) error."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9461579-90df-4a36-a09c-e5472f9cb9b6"}}},{"cell_type":"code","source":["# import pandas as pd\n\n# column_names = [\n#     \"medallion\", \"hack_license\", \"vendor_id\", \"pickup_datetime\", \"payment_type\",\n#     \"fare_amount\",\"surcharge\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"total_amount\"\n# ]\n\n# pdf = pd.read_csv(\"/databricks/datasets/nycfull/trip_data_*.csv\", header=0, names=column_names)\n# pdf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a04ff946-eccf-49d4-9a87-236385b7449b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Load the entire NYC dataset using Koalas\n\nKoalas recreates the pandas API, using Apache Spark under the hood. Using it, we are now able to load the same dataset using Koalas' equivalent read_csv function.\n\nAlso note the `ks.set_option('compute.default_index_type', 'distributed')` line below.\nPandas uses a monotonically increasing index by default (e.g., [0,1,2..]), which is the same for Koalas. However, it is not suitable for large datasets.\n\nHere, we're setting the `default_index_type` to be `distributed` - which means that the index increases monotonically, but there are indeterministic gaps in the numbers assigned. We select this index type as our dataset is relatively large and we will not explicitly require an index that monotonically increases one-by-one."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fca2811-fafb-4290-80e3-c1ab0d1708ad"}}},{"cell_type":"code","source":["import databricks.koalas as ks\nks.set_option('compute.default_index_type', 'distributed')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ad3f159-d595-4407-8727-691180829e34"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load NYC Fares Dataset\n\nIn addition to containing some common fields like the driver details, this dataset contains details on fare amount, the tolls and surcharge taxes, and the tip amount."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52f5bc99-f1bf-4230-9258-cefc7b6cac1c"}}},{"cell_type":"code","source":["column_names = [\n    \"medallion\", \"hack_license\", \"vendor_id\", \"pickup_datetime\", \"payment_type\",\n    \"fare_amount\",\"surcharge\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"total_amount\"\n]\nnyc_fares = ks.read_csv(\"dbfs:/databricks/datasets/nycfull/trip_fare_*.csv\", header=0, names=column_names)\nnyc_fares.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17c1e934-6faf-443b-8f30-82354121e151"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>hack_license</th>\n      <th>vendor_id</th>\n      <th>pickup_datetime</th>\n      <th>payment_type</th>\n      <th>fare_amount</th>\n      <th>surcharge</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>total_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8589934592</th>\n      <td>C2C60286DB4211BB6CBD046EF7F147E9</td>\n      <td>083D8CEB07A9C923F1D931FD44CF64DC</td>\n      <td>VTS</td>\n      <td>2013-01-02 12:34:00</td>\n      <td>CSH</td>\n      <td>10.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>8589934593</th>\n      <td>72481E5CAC40B72474735B4E976E7289</td>\n      <td>237241BEB99836E08F5B7938F9C861B5</td>\n      <td>VTS</td>\n      <td>2013-01-02 12:37:00</td>\n      <td>CSH</td>\n      <td>4.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>8589934594</th>\n      <td>7FF8BE125EFDEB1D1FBD4B21CFA94245</td>\n      <td>553F8EDB18F4532BB5BD8A2D4C5AC2EF</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:24:00</td>\n      <td>CSH</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.5</td>\n    </tr>\n    <tr>\n      <th>8589934595</th>\n      <td>2A206801A42E7E225C917753FC0DD27D</td>\n      <td>32DDCDE76F12CFC1EB8E4B900E85CD13</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:34:00</td>\n      <td>CSH</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>8589934596</th>\n      <td>6A5786D5702B59C611C78C846E44EAEC</td>\n      <td>C73CC5B4772C0803021069CFBB259510</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:37:00</td>\n      <td>CSH</td>\n      <td>7.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Out[5]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>hack_license</th>\n      <th>vendor_id</th>\n      <th>pickup_datetime</th>\n      <th>payment_type</th>\n      <th>fare_amount</th>\n      <th>surcharge</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>total_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8589934592</th>\n      <td>C2C60286DB4211BB6CBD046EF7F147E9</td>\n      <td>083D8CEB07A9C923F1D931FD44CF64DC</td>\n      <td>VTS</td>\n      <td>2013-01-02 12:34:00</td>\n      <td>CSH</td>\n      <td>10.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>8589934593</th>\n      <td>72481E5CAC40B72474735B4E976E7289</td>\n      <td>237241BEB99836E08F5B7938F9C861B5</td>\n      <td>VTS</td>\n      <td>2013-01-02 12:37:00</td>\n      <td>CSH</td>\n      <td>4.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>8589934594</th>\n      <td>7FF8BE125EFDEB1D1FBD4B21CFA94245</td>\n      <td>553F8EDB18F4532BB5BD8A2D4C5AC2EF</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:24:00</td>\n      <td>CSH</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.5</td>\n    </tr>\n    <tr>\n      <th>8589934595</th>\n      <td>2A206801A42E7E225C917753FC0DD27D</td>\n      <td>32DDCDE76F12CFC1EB8E4B900E85CD13</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:34:00</td>\n      <td>CSH</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>8589934596</th>\n      <td>6A5786D5702B59C611C78C846E44EAEC</td>\n      <td>C73CC5B4772C0803021069CFBB259510</td>\n      <td>VTS</td>\n      <td>2013-01-02 13:37:00</td>\n      <td>CSH</td>\n      <td>7.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_fares.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"323cf9af-8093-405c-919b-d14b5b807bf7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: (173179759, 11)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: (173179759, 11)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load NYC Trips Dataset\n\nThe trip data consists of driver details (medallion, hack_license, vendor_id) and trip details such as pickup and dropoff times, the number of passengers, trip time and distance, and the GPS coordinates of the pickup and dropoff."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db73b9ef-780e-49a2-96c8-8539f05eda1a"}}},{"cell_type":"code","source":["nyc_trips = ks.read_csv(\"dbfs:/databricks/datasets/nycfull/trip_data_*.csv\")\nnyc_trips.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e006de5c-202f-4a70-b0f2-e125c400eb5a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>hack_license</th>\n      <th>vendor_id</th>\n      <th>rate_code</th>\n      <th>store_and_fwd_flag</th>\n      <th>pickup_datetime</th>\n      <th>dropoff_datetime</th>\n      <th>passenger_count</th>\n      <th>trip_time_in_secs</th>\n      <th>trip_distance</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17179869184</th>\n      <td>3A15A182176A6707F973D236EEE23B92</td>\n      <td>0B46E6CFF11EC4C7B9676413F23453B2</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:08:00</td>\n      <td>2013-01-04 13:38:00</td>\n      <td>2</td>\n      <td>1800</td>\n      <td>4.23</td>\n      <td>-73.952377</td>\n      <td>40.791573</td>\n      <td>-73.97876</td>\n      <td>40.764816</td>\n    </tr>\n    <tr>\n      <th>17179869185</th>\n      <td>FCB1BF2054823AB4F0D2A35BB5A26A11</td>\n      <td>B57F4989DB32ED4D4CC2A9CFDED8AEDB</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:28:00</td>\n      <td>2013-01-04 13:39:00</td>\n      <td>1</td>\n      <td>660</td>\n      <td>1.28</td>\n      <td>-73.978615</td>\n      <td>40.752796</td>\n      <td>-73.990562</td>\n      <td>40.749138</td>\n    </tr>\n    <tr>\n      <th>17179869186</th>\n      <td>6C9F67DF658DC5636F9E7752F203F70A</td>\n      <td>8B526AEEA53D64E414745E1667BDD850</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:32:00</td>\n      <td>2013-01-04 13:38:00</td>\n      <td>1</td>\n      <td>360</td>\n      <td>1.37</td>\n      <td>-73.972237</td>\n      <td>40.758846</td>\n      <td>-73.983788</td>\n      <td>40.743446</td>\n    </tr>\n    <tr>\n      <th>17179869187</th>\n      <td>6B7854AB74AF4DE334E8A7932268E3C7</td>\n      <td>72B5F9275F120251A58ED88EE2F4CA5E</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:18:00</td>\n      <td>2013-01-04 13:36:00</td>\n      <td>5</td>\n      <td>1080</td>\n      <td>2.26</td>\n      <td>-74.009026</td>\n      <td>40.715946</td>\n      <td>-73.986671</td>\n      <td>40.703182</td>\n    </tr>\n    <tr>\n      <th>17179869188</th>\n      <td>7C534E2A6F98E50D524C2729B07CE60E</td>\n      <td>C72D41043CDBABC1AEB7DA1924540D83</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:33:00</td>\n      <td>2013-01-04 13:37:00</td>\n      <td>5</td>\n      <td>240</td>\n      <td>.87</td>\n      <td>-73.982254</td>\n      <td>40.745907</td>\n      <td>-73.975204</td>\n      <td>40.755817</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Out[7]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>hack_license</th>\n      <th>vendor_id</th>\n      <th>rate_code</th>\n      <th>store_and_fwd_flag</th>\n      <th>pickup_datetime</th>\n      <th>dropoff_datetime</th>\n      <th>passenger_count</th>\n      <th>trip_time_in_secs</th>\n      <th>trip_distance</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17179869184</th>\n      <td>3A15A182176A6707F973D236EEE23B92</td>\n      <td>0B46E6CFF11EC4C7B9676413F23453B2</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:08:00</td>\n      <td>2013-01-04 13:38:00</td>\n      <td>2</td>\n      <td>1800</td>\n      <td>4.23</td>\n      <td>-73.952377</td>\n      <td>40.791573</td>\n      <td>-73.97876</td>\n      <td>40.764816</td>\n    </tr>\n    <tr>\n      <th>17179869185</th>\n      <td>FCB1BF2054823AB4F0D2A35BB5A26A11</td>\n      <td>B57F4989DB32ED4D4CC2A9CFDED8AEDB</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:28:00</td>\n      <td>2013-01-04 13:39:00</td>\n      <td>1</td>\n      <td>660</td>\n      <td>1.28</td>\n      <td>-73.978615</td>\n      <td>40.752796</td>\n      <td>-73.990562</td>\n      <td>40.749138</td>\n    </tr>\n    <tr>\n      <th>17179869186</th>\n      <td>6C9F67DF658DC5636F9E7752F203F70A</td>\n      <td>8B526AEEA53D64E414745E1667BDD850</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:32:00</td>\n      <td>2013-01-04 13:38:00</td>\n      <td>1</td>\n      <td>360</td>\n      <td>1.37</td>\n      <td>-73.972237</td>\n      <td>40.758846</td>\n      <td>-73.983788</td>\n      <td>40.743446</td>\n    </tr>\n    <tr>\n      <th>17179869187</th>\n      <td>6B7854AB74AF4DE334E8A7932268E3C7</td>\n      <td>72B5F9275F120251A58ED88EE2F4CA5E</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:18:00</td>\n      <td>2013-01-04 13:36:00</td>\n      <td>5</td>\n      <td>1080</td>\n      <td>2.26</td>\n      <td>-74.009026</td>\n      <td>40.715946</td>\n      <td>-73.986671</td>\n      <td>40.703182</td>\n    </tr>\n    <tr>\n      <th>17179869188</th>\n      <td>7C534E2A6F98E50D524C2729B07CE60E</td>\n      <td>C72D41043CDBABC1AEB7DA1924540D83</td>\n      <td>VTS</td>\n      <td>1</td>\n      <td>None</td>\n      <td>2013-01-04 13:33:00</td>\n      <td>2013-01-04 13:37:00</td>\n      <td>5</td>\n      <td>240</td>\n      <td>.87</td>\n      <td>-73.982254</td>\n      <td>40.745907</td>\n      <td>-73.975204</td>\n      <td>40.755817</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_trips.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3942cce8-bccc-47e5-a10e-651d07a96dc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: (173179759, 14)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: (173179759, 14)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Preprocessing Data + Exploratory Data Analysis\n\nHaving loaded the two datasets, we can now explore it, and prepare it for a machine learning experiment.\n\nLet's take a look at the columns contained in both the DataFrames."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c901e207-3c3a-4b65-b188-0c424572957f"}}},{"cell_type":"code","source":["import pprint\n\noutput = {}\noutput['NYC Fares'] = list(nyc_fares.columns)\noutput['NYC Trips'] = list(nyc_trips.columns)\n\npprint.pprint(output)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3842bbea-a613-466f-a059-b2c087f6573d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">{&#39;NYC Fares&#39;: [&#39;medallion&#39;,\n               &#39;hack_license&#39;,\n               &#39;vendor_id&#39;,\n               &#39;pickup_datetime&#39;,\n               &#39;payment_type&#39;,\n               &#39;fare_amount&#39;,\n               &#39;surcharge&#39;,\n               &#39;mta_tax&#39;,\n               &#39;tip_amount&#39;,\n               &#39;tolls_amount&#39;,\n               &#39;total_amount&#39;],\n &#39;NYC Trips&#39;: [&#39;medallion&#39;,\n               &#39;hack_license&#39;,\n               &#39;vendor_id&#39;,\n               &#39;rate_code&#39;,\n               &#39;store_and_fwd_flag&#39;,\n               &#39;pickup_datetime&#39;,\n               &#39;dropoff_datetime&#39;,\n               &#39;passenger_count&#39;,\n               &#39;trip_time_in_secs&#39;,\n               &#39;trip_distance&#39;,\n               &#39;pickup_longitude&#39;,\n               &#39;pickup_latitude&#39;,\n               &#39;dropoff_longitude&#39;,\n               &#39;dropoff_latitude&#39;]}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;NYC Fares&#39;: [&#39;medallion&#39;,\n               &#39;hack_license&#39;,\n               &#39;vendor_id&#39;,\n               &#39;pickup_datetime&#39;,\n               &#39;payment_type&#39;,\n               &#39;fare_amount&#39;,\n               &#39;surcharge&#39;,\n               &#39;mta_tax&#39;,\n               &#39;tip_amount&#39;,\n               &#39;tolls_amount&#39;,\n               &#39;total_amount&#39;],\n &#39;NYC Trips&#39;: [&#39;medallion&#39;,\n               &#39;hack_license&#39;,\n               &#39;vendor_id&#39;,\n               &#39;rate_code&#39;,\n               &#39;store_and_fwd_flag&#39;,\n               &#39;pickup_datetime&#39;,\n               &#39;dropoff_datetime&#39;,\n               &#39;passenger_count&#39;,\n               &#39;trip_time_in_secs&#39;,\n               &#39;trip_distance&#39;,\n               &#39;pickup_longitude&#39;,\n               &#39;pickup_latitude&#39;,\n               &#39;dropoff_longitude&#39;,\n               &#39;dropoff_latitude&#39;]}\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The column `pickup_datetime` is repeated in both the tables, let's drop it from one of the them."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a8c96c3-13e4-4a48-be65-456bddd24d65"}}},{"cell_type":"code","source":["nyc_fares = nyc_fares.drop(columns=[\"pickup_datetime\"])\nnyc_fares.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fea683ff-e843-43fc-a77e-18f404e03a38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: Index([&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;, &#39;payment_type&#39;, &#39;fare_amount&#39;,\n       &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tip_amount&#39;, &#39;tolls_amount&#39;, &#39;total_amount&#39;],\n      dtype=&#39;object&#39;)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: Index([&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;, &#39;payment_type&#39;, &#39;fare_amount&#39;,\n       &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tip_amount&#39;, &#39;tolls_amount&#39;, &#39;total_amount&#39;],\n      dtype=&#39;object&#39;)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Join (flatten) the two datasets in a single dataframe\n\nWe will joing the two datasets along `medallion`, `hack_license`, and `vendor_id`, as together they uniquely define each row in both the datasets.\n\nJoining large datasets along index columns greatly improves the performance. Hence, we first need to set the index columns for the two datasets. Note that this can also be set at read time (e.g. via. `read_csv`)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ece8fd3c-da46-404f-9685-8f42eebde30e"}}},{"cell_type":"code","source":["index_column_names = [\"medallion\", \"hack_license\", \"vendor_id\"]\n\nnyc_fares = nyc_fares.set_index(index_column_names)\nnyc_trips = nyc_trips.set_index(index_column_names)\n\nprint(\"NYC Fares index columns: \", nyc_fares.index.names)\nprint(\"NYC Trips index columns: \", nyc_fares.index.names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c77b91da-24a7-4de0-bb5a-34c9450a0f1b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">NYC Fares index columns:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\nNYC Trips index columns:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">NYC Fares index columns:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\nNYC Trips index columns:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_flattened_data = nyc_fares.join(nyc_trips, how=\"inner\").dropna()\n\nprint(\"Columns: \", nyc_flattened_data.columns)\nprint(\"Index: \", nyc_flattened_data.index.names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4576288-b601-4b50-bb21-b7cab0031adc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Columns:  Index([&#39;payment_type&#39;, &#39;fare_amount&#39;, &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tip_amount&#39;,\n       &#39;tolls_amount&#39;, &#39;total_amount&#39;, &#39;rate_code&#39;, &#39;store_and_fwd_flag&#39;,\n       &#39;pickup_datetime&#39;, &#39;dropoff_datetime&#39;, &#39;passenger_count&#39;,\n       &#39;trip_time_in_secs&#39;, &#39;trip_distance&#39;, &#39;pickup_longitude&#39;,\n       &#39;pickup_latitude&#39;, &#39;dropoff_longitude&#39;, &#39;dropoff_latitude&#39;],\n      dtype=&#39;object&#39;)\nIndex:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Columns:  Index([&#39;payment_type&#39;, &#39;fare_amount&#39;, &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tip_amount&#39;,\n       &#39;tolls_amount&#39;, &#39;total_amount&#39;, &#39;rate_code&#39;, &#39;store_and_fwd_flag&#39;,\n       &#39;pickup_datetime&#39;, &#39;dropoff_datetime&#39;, &#39;passenger_count&#39;,\n       &#39;trip_time_in_secs&#39;, &#39;trip_distance&#39;, &#39;pickup_longitude&#39;,\n       &#39;pickup_latitude&#39;, &#39;dropoff_longitude&#39;, &#39;dropoff_latitude&#39;],\n      dtype=&#39;object&#39;)\nIndex:  [&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_flattened_data.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc65b786-56fc-41eb-abc2-fa78fa7ffcf8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[24]: (3207168346, 18)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: (3207168346, 18)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Joining via. Spark SQL\n\nDataFrames can also be joined using SQL queries directly."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12033a4a-efae-48a6-9361-6d7731225546"}}},{"cell_type":"code","source":["# nyc_flattened_data = ks.sql(\"\"\"\n# SELECT * \n# FROM {nyc_fares} f, {nyc_trips} t\n# WHERE \n#     f.medallion == t.medallion and \n#     f.hack_license == t.hack_license and \n#     f.vendor_id == t.vendor_id\n# \"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"732bf295-a230-4544-9180-24f63d3dcfb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Getting column statistics\n\nThe .describe() method in Koalas is similar to that in pandas, showing a statistical summary of each numerical feature:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2430096a-31e4-49be-a468-efb631ed62a1"}}},{"cell_type":"code","source":["nyc_flattened_data.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8dc06657-6ee5-41a5-83c6-4f9113d3d6ca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>surcharge</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>total_amount</th>\n      <th>rate_code</th>\n      <th>passenger_count</th>\n      <th>trip_time_in_secs</th>\n      <th>trip_distance</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.131783e+01</td>\n      <td>3.202964e-01</td>\n      <td>4.983538e-01</td>\n      <td>1.247499e+00</td>\n      <td>1.810397e-01</td>\n      <td>1.356502e+01</td>\n      <td>1.029057e+00</td>\n      <td>1.256959e+00</td>\n      <td>6.689058e+02</td>\n      <td>2.658711e+00</td>\n      <td>-7.265601e+01</td>\n      <td>4.002438e+01</td>\n      <td>-7.266756e+01</td>\n      <td>4.003151e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.049336e+00</td>\n      <td>3.694655e-01</td>\n      <td>2.864279e-02</td>\n      <td>1.969798e+00</td>\n      <td>9.763490e-01</td>\n      <td>1.081783e+01</td>\n      <td>3.526562e-01</td>\n      <td>6.072264e-01</td>\n      <td>4.790509e+02</td>\n      <td>3.158865e+00</td>\n      <td>9.794745e+00</td>\n      <td>5.395749e+00</td>\n      <td>9.748516e+00</td>\n      <td>5.370356e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>-1.793612e+02</td>\n      <td>-3.976235e+01</td>\n      <td>-1.793612e+02</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.000000e-01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>7.500000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>3.450000e+02</td>\n      <td>1.000000e+00</td>\n      <td>-7.399189e+01</td>\n      <td>4.073628e+01</td>\n      <td>-7.399132e+01</td>\n      <td>4.073506e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.000000e-01</td>\n      <td>8.000000e-01</td>\n      <td>0.000000e+00</td>\n      <td>1.050000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>5.530000e+02</td>\n      <td>1.700000e+00</td>\n      <td>-7.398165e+01</td>\n      <td>4.075348e+01</td>\n      <td>-7.398008e+01</td>\n      <td>4.075395e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.300000e+01</td>\n      <td>5.000000e-01</td>\n      <td>5.000000e-01</td>\n      <td>2.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.500000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>8.610000e+02</td>\n      <td>3.000000e+00</td>\n      <td>-7.396703e+01</td>\n      <td>4.076771e+01</td>\n      <td>-7.396407e+01</td>\n      <td>4.076838e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000e+02</td>\n      <td>1.250000e+01</td>\n      <td>5.000000e-01</td>\n      <td>1.500000e+02</td>\n      <td>2.000000e+01</td>\n      <td>6.500000e+02</td>\n      <td>2.100000e+02</td>\n      <td>6.000000e+00</td>\n      <td>1.026500e+04</td>\n      <td>1.000000e+02</td>\n      <td>1.124042e+02</td>\n      <td>8.251405e+01</td>\n      <td>1.114939e+02</td>\n      <td>8.351669e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Out[25]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>surcharge</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>total_amount</th>\n      <th>rate_code</th>\n      <th>passenger_count</th>\n      <th>trip_time_in_secs</th>\n      <th>trip_distance</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n      <td>3.207168e+09</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.131783e+01</td>\n      <td>3.202964e-01</td>\n      <td>4.983538e-01</td>\n      <td>1.247499e+00</td>\n      <td>1.810397e-01</td>\n      <td>1.356502e+01</td>\n      <td>1.029057e+00</td>\n      <td>1.256959e+00</td>\n      <td>6.689058e+02</td>\n      <td>2.658711e+00</td>\n      <td>-7.265601e+01</td>\n      <td>4.002438e+01</td>\n      <td>-7.266756e+01</td>\n      <td>4.003151e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.049336e+00</td>\n      <td>3.694655e-01</td>\n      <td>2.864279e-02</td>\n      <td>1.969798e+00</td>\n      <td>9.763490e-01</td>\n      <td>1.081783e+01</td>\n      <td>3.526562e-01</td>\n      <td>6.072264e-01</td>\n      <td>4.790509e+02</td>\n      <td>3.158865e+00</td>\n      <td>9.794745e+00</td>\n      <td>5.395749e+00</td>\n      <td>9.748516e+00</td>\n      <td>5.370356e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>-1.793612e+02</td>\n      <td>-3.976235e+01</td>\n      <td>-1.793612e+02</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.000000e-01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>7.500000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>3.450000e+02</td>\n      <td>1.000000e+00</td>\n      <td>-7.399189e+01</td>\n      <td>4.073628e+01</td>\n      <td>-7.399132e+01</td>\n      <td>4.073506e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.000000e-01</td>\n      <td>8.000000e-01</td>\n      <td>0.000000e+00</td>\n      <td>1.050000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>5.530000e+02</td>\n      <td>1.700000e+00</td>\n      <td>-7.398165e+01</td>\n      <td>4.075348e+01</td>\n      <td>-7.398008e+01</td>\n      <td>4.075395e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.300000e+01</td>\n      <td>5.000000e-01</td>\n      <td>5.000000e-01</td>\n      <td>2.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.500000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>8.610000e+02</td>\n      <td>3.000000e+00</td>\n      <td>-7.396703e+01</td>\n      <td>4.076771e+01</td>\n      <td>-7.396407e+01</td>\n      <td>4.076838e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000e+02</td>\n      <td>1.250000e+01</td>\n      <td>5.000000e-01</td>\n      <td>1.500000e+02</td>\n      <td>2.000000e+01</td>\n      <td>6.500000e+02</td>\n      <td>2.100000e+02</td>\n      <td>6.000000e+00</td>\n      <td>1.026500e+04</td>\n      <td>1.000000e+02</td>\n      <td>1.124042e+02</td>\n      <td>8.251405e+01</td>\n      <td>1.114939e+02</td>\n      <td>8.351669e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Identify missing values in the DataFrame, if any."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eebdf21f-7ad1-4690-b7c5-eeb6cc4ef393"}}},{"cell_type":"code","source":["nyc_flattened_data.isna().sum()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36a4c81d-47f4-4999-a313-7f3ac8ec2a4e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[26]: payment_type          0\nfare_amount           0\nsurcharge             0\nmta_tax               0\ntip_amount            0\ntolls_amount          0\ntotal_amount          0\nrate_code             0\nstore_and_fwd_flag    0\npickup_datetime       0\ndropoff_datetime      0\npassenger_count       0\ntrip_time_in_secs     0\ntrip_distance         0\npickup_longitude      0\npickup_latitude       0\ndropoff_longitude     0\ndropoff_latitude      0\ndtype: int64</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: payment_type          0\nfare_amount           0\nsurcharge             0\nmta_tax               0\ntip_amount            0\ntolls_amount          0\ntotal_amount          0\nrate_code             0\nstore_and_fwd_flag    0\npickup_datetime       0\ndropoff_datetime      0\npassenger_count       0\ntrip_time_in_secs     0\ntrip_distance         0\npickup_longitude      0\npickup_latitude       0\ndropoff_longitude     0\ndropoff_latitude      0\ndtype: int64</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Drill down into column specific statistics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e00fa4be-a16e-4304-b43b-412c27e5cb69"}}},{"cell_type":"code","source":["nyc_flattened_data['store_and_fwd_flag'].value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cfba49c-c731-4541-87b9-37d44d84f87a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: N    3138138506\nY      69029840\nName: store_and_fwd_flag, dtype: int64</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: N    3138138506\nY      69029840\nName: store_and_fwd_flag, dtype: int64</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_flattened_data[\"passenger_count\"].plot.hist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c75f0e8-8a09-4043-875c-d023d30c9292"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/d7bda1be-7ade-4669-b826-cb53af63218d.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"markdown","source":["## Prepare the target column\n\nGiven the driver and trip details, into which bin will a passenger tip fall? What is the current distribution of tips? Let's bucketize the tips in the following classes:\n\n```\nClass 0 : Tip = $0\nClass 1 : Tip > $0 and Tip < $1\nClass 2 : Tip >= $1 and Tip < $5\nClass 3 : Tip >= $5 and Tip < $20\nClass 4 : Tip >= $20\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2bc6167-9eb5-4ed4-93cb-fd2bf8358f3b"}}},{"cell_type":"code","source":["def binning(row):\n    if row.tip_amount == 0:\n        return 0\n    elif row.tip_amount < 1:\n        return 1\n    elif row.tip_amount < 5:\n        return 2\n    elif row.tip_amount < 20:\n        return 3\n    else:\n        return 4\n\nbins = nyc_flattened_data.apply(binning, axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6bfc1f6-854a-416b-9cd8-868e758f4369"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["nyc_flattened_data.sample(frac=0.001, random_state=12345).reset_index().to_parquet(\"dbfs:/databricks/datasets/nycfull/nyc_joined_sampled.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1aff584e-94f0-4fca-a3e5-74859c7887d3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["kdf = ks.read_parquet(\"dbfs:/databricks/datasets/nycfull/nyc_joined_sampled.parquet\")\nkdf.shape\nnyc_flattened_data = kdf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9f9c1cc-33c0-47f6-b471-4f87bbdc8f1e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["bins.plot.hist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"141a090d-0e69-4968-a0a9-6b708116bfe6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/818d4865-d4cc-478e-8198-f57027bc25b3.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"markdown","source":["The data is imbalanced for the chosen buckets. So we would need to handle this (via. assigning weights to the classes).\nWe can also slightly change the problem to simplify this. Instead of identifying which bucket of tips a trip will fall into, let's instead figure out that given trip information, would it result in a non-zero tip amount. This is a binary classification problem now."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bee2ce5-7d78-4d28-acd4-ff280155cac0"}}},{"cell_type":"code","source":["binary_bins = nyc_flattened_data.apply(lambda row: 0 if row.tip_amount > 0 else 1, axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd1545c4-0b4b-4cdb-909a-f0a6514509ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["binary_bins.plot.hist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fc5d7b8-f285-4e41-b2df-a4abd6d5f0f6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/145143ac-f95b-4b37-922c-cf761c7389bc.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"markdown","source":["Koalas disallows the operations on different DataFrames (or Series) by default to prevent expensive operations. It internally performs a join operation which can be expensive in general. To override this behavior we need to enable the property `compute.ops_on_diff_frames`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27c35a11-f83d-49ed-9101-b124c4f3cbb5"}}},{"cell_type":"code","source":["ks.set_option(\"compute.ops_on_diff_frames\", True)\nnyc_flattened_data['target'] = binary_bins\nnyc_flattened_data = nyc_flattened_data.drop(\"tip_amount\")\n\nnyc_flattened_data.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"baa3aa8f-0526-4ac1-a75d-27ff40eb8e01"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: Index([&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;, &#39;payment_type&#39;, &#39;fare_amount&#39;,\n       &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tolls_amount&#39;, &#39;total_amount&#39;, &#39;rate_code&#39;,\n       &#39;store_and_fwd_flag&#39;, &#39;pickup_datetime&#39;, &#39;dropoff_datetime&#39;,\n       &#39;passenger_count&#39;, &#39;trip_time_in_secs&#39;, &#39;trip_distance&#39;,\n       &#39;pickup_longitude&#39;, &#39;pickup_latitude&#39;, &#39;dropoff_longitude&#39;,\n       &#39;dropoff_latitude&#39;, &#39;target&#39;],\n      dtype=&#39;object&#39;)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: Index([&#39;medallion&#39;, &#39;hack_license&#39;, &#39;vendor_id&#39;, &#39;payment_type&#39;, &#39;fare_amount&#39;,\n       &#39;surcharge&#39;, &#39;mta_tax&#39;, &#39;tolls_amount&#39;, &#39;total_amount&#39;, &#39;rate_code&#39;,\n       &#39;store_and_fwd_flag&#39;, &#39;pickup_datetime&#39;, &#39;dropoff_datetime&#39;,\n       &#39;passenger_count&#39;, &#39;trip_time_in_secs&#39;, &#39;trip_distance&#39;,\n       &#39;pickup_longitude&#39;, &#39;pickup_latitude&#39;, &#39;dropoff_longitude&#39;,\n       &#39;dropoff_latitude&#39;, &#39;target&#39;],\n      dtype=&#39;object&#39;)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's look at the correlation matrix for the combined DataFrame, to see if there's anything obvious that is correlated with the target column. This gives us a good estimate if there are leaky features, as they will rank very high in the correlation matrix."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7063bec1-941d-4870-9634-92f7f0dc7e71"}}},{"cell_type":"code","source":["corr = nyc_flattened_data.dropna().corr()\ncorr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c7db7a3-be93-4b35-9db8-b1a04966f4bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<style  type=\"text/css\" >\n    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col0 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col1 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col2 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col3 {\n            background-color:  #f08b6e;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col4 {\n            background-color:  #b70d28;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col5 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col7 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col8 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col13 {\n            background-color:  #d1dae9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col0 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col1 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col2 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col3 {\n            background-color:  #d5dbe5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col4 {\n            background-color:  #dbdcde;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col6 {\n            background-color:  #e3d9d3;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col13 {\n            background-color:  #dadce0;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col0 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col1 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col2 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col3 {\n            background-color:  #b7cff9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col4 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col13 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col0 {\n            background-color:  #f08b6e;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col1 {\n            background-color:  #d5dbe5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col2 {\n            background-color:  #b7cff9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col3 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col4 {\n            background-color:  #eb7d62;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col5 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col7 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col13 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col0 {\n            background-color:  #b70d28;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col1 {\n            background-color:  #dbdcde;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col2 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col3 {\n            background-color:  #eb7d62;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col4 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col5 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col6 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col7 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col8 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col13 {\n            background-color:  #c1d4f4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col0 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col3 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col4 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col5 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col6 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col7 {\n            background-color:  #edd1c2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col8 {\n            background-color:  #f3c8b2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col1 {\n            background-color:  #e3d9d3;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col4 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col5 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col6 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col7 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col0 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col3 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col4 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col5 {\n            background-color:  #edd1c2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col6 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col7 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col8 {\n            background-color:  #de614d;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col0 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col1 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col3 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col4 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col5 {\n            background-color:  #f3c8b2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col6 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col7 {\n            background-color:  #de614d;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col8 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col3 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col4 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col7 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col8 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col9 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col10 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col11 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col12 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col13 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col0 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col2 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col4 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col9 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col10 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col11 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col12 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col3 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col4 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col9 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col10 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col11 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col12 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col13 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col0 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col2 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col4 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col7 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col8 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col9 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col10 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col11 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col12 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col0 {\n            background-color:  #d1dae9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col1 {\n            background-color:  #dadce0;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col2 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col3 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col4 {\n            background-color:  #c1d4f4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col13 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }</style><table id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fare_amount</th>        <th class=\"col_heading level0 col1\" >surcharge</th>        <th class=\"col_heading level0 col2\" >mta_tax</th>        <th class=\"col_heading level0 col3\" >tolls_amount</th>        <th class=\"col_heading level0 col4\" >total_amount</th>        <th class=\"col_heading level0 col5\" >rate_code</th>        <th class=\"col_heading level0 col6\" >passenger_count</th>        <th class=\"col_heading level0 col7\" >trip_time_in_secs</th>        <th class=\"col_heading level0 col8\" >trip_distance</th>        <th class=\"col_heading level0 col9\" >pickup_longitude</th>        <th class=\"col_heading level0 col10\" >pickup_latitude</th>        <th class=\"col_heading level0 col11\" >dropoff_longitude</th>        <th class=\"col_heading level0 col12\" >dropoff_latitude</th>        <th class=\"col_heading level0 col13\" >target</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row0\" class=\"row_heading level0 row0\" >fare_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col0\" class=\"data row0 col0\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col1\" class=\"data row0 col1\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col2\" class=\"data row0 col2\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col3\" class=\"data row0 col3\" >0.57</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col4\" class=\"data row0 col4\" >0.98</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col5\" class=\"data row0 col5\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col6\" class=\"data row0 col6\" >0.0064</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col7\" class=\"data row0 col7\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col8\" class=\"data row0 col8\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col9\" class=\"data row0 col9\" >0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col10\" class=\"data row0 col10\" >-0.00078</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col11\" class=\"data row0 col11\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col12\" class=\"data row0 col12\" >-0.00041</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col13\" class=\"data row0 col13\" >-0.091</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row1\" class=\"row_heading level0 row1\" >surcharge</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col0\" class=\"data row1 col0\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col1\" class=\"data row1 col1\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col2\" class=\"data row1 col2\" >0.039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col3\" class=\"data row1 col3\" >-0.058</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col4\" class=\"data row1 col4\" >-0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col5\" class=\"data row1 col5\" >0.0042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col6\" class=\"data row1 col6\" >0.051</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col7\" class=\"data row1 col7\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col8\" class=\"data row1 col8\" >0.029</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col9\" class=\"data row1 col9\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col10\" class=\"data row1 col10\" >-0.0034</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col11\" class=\"data row1 col11\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col12\" class=\"data row1 col12\" >-0.0033</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col13\" class=\"data row1 col13\" >-0.02</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row2\" class=\"row_heading level0 row2\" >mta_tax</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col0\" class=\"data row2 col0\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col1\" class=\"data row2 col1\" >0.039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col2\" class=\"data row2 col2\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col3\" class=\"data row2 col3\" >-0.25</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col4\" class=\"data row2 col4\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col5\" class=\"data row2 col5\" >-0.0069</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col6\" class=\"data row2 col6\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col7\" class=\"data row2 col7\" >-0.0026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col8\" class=\"data row2 col8\" >-0.0052</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col9\" class=\"data row2 col9\" >-0.00059</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col10\" class=\"data row2 col10\" >0.00061</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col11\" class=\"data row2 col11\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col12\" class=\"data row2 col12\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col13\" class=\"data row2 col13\" >0.014</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row3\" class=\"row_heading level0 row3\" >tolls_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col0\" class=\"data row3 col0\" >0.57</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col1\" class=\"data row3 col1\" >-0.058</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col2\" class=\"data row3 col2\" >-0.25</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col3\" class=\"data row3 col3\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col4\" class=\"data row3 col4\" >0.63</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col5\" class=\"data row3 col5\" >0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col6\" class=\"data row3 col6\" >0.0032</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col7\" class=\"data row3 col7\" >0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col8\" class=\"data row3 col8\" >0.026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col9\" class=\"data row3 col9\" >-0.00043</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col10\" class=\"data row3 col10\" >0.00048</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col11\" class=\"data row3 col11\" >-0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col12\" class=\"data row3 col12\" >0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col13\" class=\"data row3 col13\" >-0.049</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row4\" class=\"row_heading level0 row4\" >total_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col0\" class=\"data row4 col0\" >0.98</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col1\" class=\"data row4 col1\" >-0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col2\" class=\"data row4 col2\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col3\" class=\"data row4 col3\" >0.63</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col4\" class=\"data row4 col4\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col5\" class=\"data row4 col5\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col6\" class=\"data row4 col6\" >0.0083</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col7\" class=\"data row4 col7\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col8\" class=\"data row4 col8\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col9\" class=\"data row4 col9\" >0.00079</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col10\" class=\"data row4 col10\" >-0.00082</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col11\" class=\"data row4 col11\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col12\" class=\"data row4 col12\" >-0.00042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col13\" class=\"data row4 col13\" >-0.19</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row5\" class=\"row_heading level0 row5\" >rate_code</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col0\" class=\"data row5 col0\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col1\" class=\"data row5 col1\" >0.0042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col2\" class=\"data row5 col2\" >-0.0069</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col3\" class=\"data row5 col3\" >0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col4\" class=\"data row5 col4\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col5\" class=\"data row5 col5\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col6\" class=\"data row5 col6\" >0.015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col7\" class=\"data row5 col7\" >0.14</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col8\" class=\"data row5 col8\" >0.22</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col9\" class=\"data row5 col9\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col10\" class=\"data row5 col10\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col11\" class=\"data row5 col11\" >0.0006</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col12\" class=\"data row5 col12\" >-0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col13\" class=\"data row5 col13\" >-0.00071</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row6\" class=\"row_heading level0 row6\" >passenger_count</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col0\" class=\"data row6 col0\" >0.0064</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col1\" class=\"data row6 col1\" >0.051</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col2\" class=\"data row6 col2\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col3\" class=\"data row6 col3\" >0.0032</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col4\" class=\"data row6 col4\" >0.0083</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col5\" class=\"data row6 col5\" >0.015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col6\" class=\"data row6 col6\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col7\" class=\"data row6 col7\" >0.045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col8\" class=\"data row6 col8\" >0.03</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col9\" class=\"data row6 col9\" >-0.0011</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col10\" class=\"data row6 col10\" >0.00095</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col11\" class=\"data row6 col11\" >-0.0019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col12\" class=\"data row6 col12\" >0.0018</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col13\" class=\"data row6 col13\" >-0.002</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row7\" class=\"row_heading level0 row7\" >trip_time_in_secs</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col0\" class=\"data row7 col0\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col1\" class=\"data row7 col1\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col2\" class=\"data row7 col2\" >-0.0026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col3\" class=\"data row7 col3\" >0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col4\" class=\"data row7 col4\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col5\" class=\"data row7 col5\" >0.14</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col6\" class=\"data row7 col6\" >0.045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col7\" class=\"data row7 col7\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col8\" class=\"data row7 col8\" >0.75</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col9\" class=\"data row7 col9\" >0.0017</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col10\" class=\"data row7 col10\" >-0.0016</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col11\" class=\"data row7 col11\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col12\" class=\"data row7 col12\" >0.0028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col13\" class=\"data row7 col13\" >-0.0015</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row8\" class=\"row_heading level0 row8\" >trip_distance</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col0\" class=\"data row8 col0\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col1\" class=\"data row8 col1\" >0.029</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col2\" class=\"data row8 col2\" >-0.0052</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col3\" class=\"data row8 col3\" >0.026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col4\" class=\"data row8 col4\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col5\" class=\"data row8 col5\" >0.22</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col6\" class=\"data row8 col6\" >0.03</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col7\" class=\"data row8 col7\" >0.75</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col8\" class=\"data row8 col8\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col9\" class=\"data row8 col9\" >0.0039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col10\" class=\"data row8 col10\" >-0.0035</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col11\" class=\"data row8 col11\" >-0.00021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col12\" class=\"data row8 col12\" >0.00046</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col13\" class=\"data row8 col13\" >-0.0021</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row9\" class=\"row_heading level0 row9\" >pickup_longitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col0\" class=\"data row9 col0\" >0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col1\" class=\"data row9 col1\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col2\" class=\"data row9 col2\" >-0.00059</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col3\" class=\"data row9 col3\" >-0.00043</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col4\" class=\"data row9 col4\" >0.00079</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col5\" class=\"data row9 col5\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col6\" class=\"data row9 col6\" >-0.0011</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col7\" class=\"data row9 col7\" >0.0017</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col8\" class=\"data row9 col8\" >0.0039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col9\" class=\"data row9 col9\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col10\" class=\"data row9 col10\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col11\" class=\"data row9 col11\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col12\" class=\"data row9 col12\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col13\" class=\"data row9 col13\" >0.00049</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row10\" class=\"row_heading level0 row10\" >pickup_latitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col0\" class=\"data row10 col0\" >-0.00078</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col1\" class=\"data row10 col1\" >-0.0034</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col2\" class=\"data row10 col2\" >0.00061</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col3\" class=\"data row10 col3\" >0.00048</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col4\" class=\"data row10 col4\" >-0.00082</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col5\" class=\"data row10 col5\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col6\" class=\"data row10 col6\" >0.00095</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col7\" class=\"data row10 col7\" >-0.0016</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col8\" class=\"data row10 col8\" >-0.0035</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col9\" class=\"data row10 col9\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col10\" class=\"data row10 col10\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col11\" class=\"data row10 col11\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col12\" class=\"data row10 col12\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col13\" class=\"data row10 col13\" >-0.00045</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row11\" class=\"row_heading level0 row11\" >dropoff_longitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col0\" class=\"data row11 col0\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col1\" class=\"data row11 col1\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col2\" class=\"data row11 col2\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col3\" class=\"data row11 col3\" >-0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col4\" class=\"data row11 col4\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col5\" class=\"data row11 col5\" >0.0006</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col6\" class=\"data row11 col6\" >-0.0019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col7\" class=\"data row11 col7\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col8\" class=\"data row11 col8\" >-0.00021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col9\" class=\"data row11 col9\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col10\" class=\"data row11 col10\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col11\" class=\"data row11 col11\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col12\" class=\"data row11 col12\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col13\" class=\"data row11 col13\" >0.00044</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row12\" class=\"row_heading level0 row12\" >dropoff_latitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col0\" class=\"data row12 col0\" >-0.00041</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col1\" class=\"data row12 col1\" >-0.0033</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col2\" class=\"data row12 col2\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col3\" class=\"data row12 col3\" >0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col4\" class=\"data row12 col4\" >-0.00042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col5\" class=\"data row12 col5\" >-0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col6\" class=\"data row12 col6\" >0.0018</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col7\" class=\"data row12 col7\" >0.0028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col8\" class=\"data row12 col8\" >0.00046</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col9\" class=\"data row12 col9\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col10\" class=\"data row12 col10\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col11\" class=\"data row12 col11\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col12\" class=\"data row12 col12\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col13\" class=\"data row12 col13\" >-0.0004</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row13\" class=\"row_heading level0 row13\" >target</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col0\" class=\"data row13 col0\" >-0.091</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col1\" class=\"data row13 col1\" >-0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col2\" class=\"data row13 col2\" >0.014</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col3\" class=\"data row13 col3\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col4\" class=\"data row13 col4\" >-0.19</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col5\" class=\"data row13 col5\" >-0.00071</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col6\" class=\"data row13 col6\" >-0.002</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col7\" class=\"data row13 col7\" >-0.0015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col8\" class=\"data row13 col8\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col9\" class=\"data row13 col9\" >0.00049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col10\" class=\"data row13 col10\" >-0.00045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col11\" class=\"data row13 col11\" >0.00044</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col12\" class=\"data row13 col12\" >-0.0004</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col13\" class=\"data row13 col13\" >1</td>\n            </tr>\n    </tbody></table>","textData":"<div class=\"ansiout\">Out[30]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style  type=\"text/css\" >\n    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col0 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col1 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col2 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col3 {\n            background-color:  #f08b6e;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col4 {\n            background-color:  #b70d28;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col5 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col7 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col8 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col13 {\n            background-color:  #d1dae9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col0 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col1 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col2 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col3 {\n            background-color:  #d5dbe5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col4 {\n            background-color:  #dbdcde;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col6 {\n            background-color:  #e3d9d3;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col13 {\n            background-color:  #dadce0;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col0 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col1 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col2 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col3 {\n            background-color:  #b7cff9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col4 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col13 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col0 {\n            background-color:  #f08b6e;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col1 {\n            background-color:  #d5dbe5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col2 {\n            background-color:  #b7cff9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col3 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col4 {\n            background-color:  #eb7d62;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col5 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col7 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col13 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col0 {\n            background-color:  #b70d28;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col1 {\n            background-color:  #dbdcde;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col2 {\n            background-color:  #aec9fc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col3 {\n            background-color:  #eb7d62;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col4 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col5 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col6 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col7 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col8 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col13 {\n            background-color:  #c1d4f4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col0 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col3 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col4 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col5 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col6 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col7 {\n            background-color:  #edd1c2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col8 {\n            background-color:  #f3c8b2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col1 {\n            background-color:  #e3d9d3;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col4 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col5 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col6 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col7 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col8 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col9 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col10 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col0 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col3 {\n            background-color:  #dfdbd9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col4 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col5 {\n            background-color:  #edd1c2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col6 {\n            background-color:  #e2dad5;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col7 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col8 {\n            background-color:  #de614d;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col0 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col1 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col3 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col4 {\n            background-color:  #e1dad6;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col5 {\n            background-color:  #f3c8b2;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col6 {\n            background-color:  #e0dbd8;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col7 {\n            background-color:  #de614d;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col8 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col11 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col12 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col3 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col4 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col7 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col8 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col9 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col10 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col11 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col12 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col13 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col0 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col2 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col4 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col9 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col10 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col11 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col12 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col0 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col1 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col2 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col3 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col4 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col5 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col9 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col10 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col11 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col12 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col13 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col0 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col1 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col2 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col3 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col4 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col6 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col7 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col8 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col9 {\n            background-color:  #3f53c6;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col10 {\n            background-color:  #ba162b;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col11 {\n            background-color:  #3b4cc0;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col12 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col13 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col0 {\n            background-color:  #d1dae9;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col1 {\n            background-color:  #dadce0;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col2 {\n            background-color:  #dedcdb;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col3 {\n            background-color:  #d6dce4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col4 {\n            background-color:  #c1d4f4;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col5 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col6 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col7 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col8 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col9 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col10 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col11 {\n            background-color:  #dddcdc;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col12 {\n            background-color:  #dcdddd;\n            color:  #000000;\n        }    #T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col13 {\n            background-color:  #b40426;\n            color:  #f1f1f1;\n        }</style><table id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fare_amount</th>        <th class=\"col_heading level0 col1\" >surcharge</th>        <th class=\"col_heading level0 col2\" >mta_tax</th>        <th class=\"col_heading level0 col3\" >tolls_amount</th>        <th class=\"col_heading level0 col4\" >total_amount</th>        <th class=\"col_heading level0 col5\" >rate_code</th>        <th class=\"col_heading level0 col6\" >passenger_count</th>        <th class=\"col_heading level0 col7\" >trip_time_in_secs</th>        <th class=\"col_heading level0 col8\" >trip_distance</th>        <th class=\"col_heading level0 col9\" >pickup_longitude</th>        <th class=\"col_heading level0 col10\" >pickup_latitude</th>        <th class=\"col_heading level0 col11\" >dropoff_longitude</th>        <th class=\"col_heading level0 col12\" >dropoff_latitude</th>        <th class=\"col_heading level0 col13\" >target</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row0\" class=\"row_heading level0 row0\" >fare_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col0\" class=\"data row0 col0\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col1\" class=\"data row0 col1\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col2\" class=\"data row0 col2\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col3\" class=\"data row0 col3\" >0.57</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col4\" class=\"data row0 col4\" >0.98</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col5\" class=\"data row0 col5\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col6\" class=\"data row0 col6\" >0.0064</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col7\" class=\"data row0 col7\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col8\" class=\"data row0 col8\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col9\" class=\"data row0 col9\" >0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col10\" class=\"data row0 col10\" >-0.00078</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col11\" class=\"data row0 col11\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col12\" class=\"data row0 col12\" >-0.00041</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow0_col13\" class=\"data row0 col13\" >-0.091</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row1\" class=\"row_heading level0 row1\" >surcharge</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col0\" class=\"data row1 col0\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col1\" class=\"data row1 col1\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col2\" class=\"data row1 col2\" >0.039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col3\" class=\"data row1 col3\" >-0.058</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col4\" class=\"data row1 col4\" >-0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col5\" class=\"data row1 col5\" >0.0042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col6\" class=\"data row1 col6\" >0.051</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col7\" class=\"data row1 col7\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col8\" class=\"data row1 col8\" >0.029</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col9\" class=\"data row1 col9\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col10\" class=\"data row1 col10\" >-0.0034</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col11\" class=\"data row1 col11\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col12\" class=\"data row1 col12\" >-0.0033</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow1_col13\" class=\"data row1 col13\" >-0.02</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row2\" class=\"row_heading level0 row2\" >mta_tax</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col0\" class=\"data row2 col0\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col1\" class=\"data row2 col1\" >0.039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col2\" class=\"data row2 col2\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col3\" class=\"data row2 col3\" >-0.25</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col4\" class=\"data row2 col4\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col5\" class=\"data row2 col5\" >-0.0069</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col6\" class=\"data row2 col6\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col7\" class=\"data row2 col7\" >-0.0026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col8\" class=\"data row2 col8\" >-0.0052</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col9\" class=\"data row2 col9\" >-0.00059</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col10\" class=\"data row2 col10\" >0.00061</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col11\" class=\"data row2 col11\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col12\" class=\"data row2 col12\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow2_col13\" class=\"data row2 col13\" >0.014</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row3\" class=\"row_heading level0 row3\" >tolls_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col0\" class=\"data row3 col0\" >0.57</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col1\" class=\"data row3 col1\" >-0.058</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col2\" class=\"data row3 col2\" >-0.25</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col3\" class=\"data row3 col3\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col4\" class=\"data row3 col4\" >0.63</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col5\" class=\"data row3 col5\" >0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col6\" class=\"data row3 col6\" >0.0032</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col7\" class=\"data row3 col7\" >0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col8\" class=\"data row3 col8\" >0.026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col9\" class=\"data row3 col9\" >-0.00043</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col10\" class=\"data row3 col10\" >0.00048</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col11\" class=\"data row3 col11\" >-0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col12\" class=\"data row3 col12\" >0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow3_col13\" class=\"data row3 col13\" >-0.049</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row4\" class=\"row_heading level0 row4\" >total_amount</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col0\" class=\"data row4 col0\" >0.98</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col1\" class=\"data row4 col1\" >-0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col2\" class=\"data row4 col2\" >-0.31</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col3\" class=\"data row4 col3\" >0.63</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col4\" class=\"data row4 col4\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col5\" class=\"data row4 col5\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col6\" class=\"data row4 col6\" >0.0083</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col7\" class=\"data row4 col7\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col8\" class=\"data row4 col8\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col9\" class=\"data row4 col9\" >0.00079</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col10\" class=\"data row4 col10\" >-0.00082</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col11\" class=\"data row4 col11\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col12\" class=\"data row4 col12\" >-0.00042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow4_col13\" class=\"data row4 col13\" >-0.19</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row5\" class=\"row_heading level0 row5\" >rate_code</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col0\" class=\"data row5 col0\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col1\" class=\"data row5 col1\" >0.0042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col2\" class=\"data row5 col2\" >-0.0069</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col3\" class=\"data row5 col3\" >0.013</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col4\" class=\"data row5 col4\" >0.019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col5\" class=\"data row5 col5\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col6\" class=\"data row5 col6\" >0.015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col7\" class=\"data row5 col7\" >0.14</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col8\" class=\"data row5 col8\" >0.22</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col9\" class=\"data row5 col9\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col10\" class=\"data row5 col10\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col11\" class=\"data row5 col11\" >0.0006</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col12\" class=\"data row5 col12\" >-0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow5_col13\" class=\"data row5 col13\" >-0.00071</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row6\" class=\"row_heading level0 row6\" >passenger_count</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col0\" class=\"data row6 col0\" >0.0064</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col1\" class=\"data row6 col1\" >0.051</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col2\" class=\"data row6 col2\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col3\" class=\"data row6 col3\" >0.0032</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col4\" class=\"data row6 col4\" >0.0083</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col5\" class=\"data row6 col5\" >0.015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col6\" class=\"data row6 col6\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col7\" class=\"data row6 col7\" >0.045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col8\" class=\"data row6 col8\" >0.03</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col9\" class=\"data row6 col9\" >-0.0011</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col10\" class=\"data row6 col10\" >0.00095</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col11\" class=\"data row6 col11\" >-0.0019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col12\" class=\"data row6 col12\" >0.0018</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow6_col13\" class=\"data row6 col13\" >-0.002</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row7\" class=\"row_heading level0 row7\" >trip_time_in_secs</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col0\" class=\"data row7 col0\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col1\" class=\"data row7 col1\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col2\" class=\"data row7 col2\" >-0.0026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col3\" class=\"data row7 col3\" >0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col4\" class=\"data row7 col4\" >0.028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col5\" class=\"data row7 col5\" >0.14</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col6\" class=\"data row7 col6\" >0.045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col7\" class=\"data row7 col7\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col8\" class=\"data row7 col8\" >0.75</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col9\" class=\"data row7 col9\" >0.0017</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col10\" class=\"data row7 col10\" >-0.0016</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col11\" class=\"data row7 col11\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col12\" class=\"data row7 col12\" >0.0028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow7_col13\" class=\"data row7 col13\" >-0.0015</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row8\" class=\"row_heading level0 row8\" >trip_distance</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col0\" class=\"data row8 col0\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col1\" class=\"data row8 col1\" >0.029</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col2\" class=\"data row8 col2\" >-0.0052</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col3\" class=\"data row8 col3\" >0.026</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col4\" class=\"data row8 col4\" >0.038</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col5\" class=\"data row8 col5\" >0.22</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col6\" class=\"data row8 col6\" >0.03</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col7\" class=\"data row8 col7\" >0.75</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col8\" class=\"data row8 col8\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col9\" class=\"data row8 col9\" >0.0039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col10\" class=\"data row8 col10\" >-0.0035</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col11\" class=\"data row8 col11\" >-0.00021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col12\" class=\"data row8 col12\" >0.00046</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow8_col13\" class=\"data row8 col13\" >-0.0021</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row9\" class=\"row_heading level0 row9\" >pickup_longitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col0\" class=\"data row9 col0\" >0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col1\" class=\"data row9 col1\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col2\" class=\"data row9 col2\" >-0.00059</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col3\" class=\"data row9 col3\" >-0.00043</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col4\" class=\"data row9 col4\" >0.00079</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col5\" class=\"data row9 col5\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col6\" class=\"data row9 col6\" >-0.0011</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col7\" class=\"data row9 col7\" >0.0017</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col8\" class=\"data row9 col8\" >0.0039</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col9\" class=\"data row9 col9\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col10\" class=\"data row9 col10\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col11\" class=\"data row9 col11\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col12\" class=\"data row9 col12\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow9_col13\" class=\"data row9 col13\" >0.00049</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row10\" class=\"row_heading level0 row10\" >pickup_latitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col0\" class=\"data row10 col0\" >-0.00078</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col1\" class=\"data row10 col1\" >-0.0034</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col2\" class=\"data row10 col2\" >0.00061</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col3\" class=\"data row10 col3\" >0.00048</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col4\" class=\"data row10 col4\" >-0.00082</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col5\" class=\"data row10 col5\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col6\" class=\"data row10 col6\" >0.00095</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col7\" class=\"data row10 col7\" >-0.0016</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col8\" class=\"data row10 col8\" >-0.0035</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col9\" class=\"data row10 col9\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col10\" class=\"data row10 col10\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col11\" class=\"data row10 col11\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col12\" class=\"data row10 col12\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow10_col13\" class=\"data row10 col13\" >-0.00045</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row11\" class=\"row_heading level0 row11\" >dropoff_longitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col0\" class=\"data row11 col0\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col1\" class=\"data row11 col1\" >0.003</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col2\" class=\"data row11 col2\" >-0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col3\" class=\"data row11 col3\" >-0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col4\" class=\"data row11 col4\" >0.00037</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col5\" class=\"data row11 col5\" >0.0006</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col6\" class=\"data row11 col6\" >-0.0019</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col7\" class=\"data row11 col7\" >-0.0031</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col8\" class=\"data row11 col8\" >-0.00021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col9\" class=\"data row11 col9\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col10\" class=\"data row11 col10\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col11\" class=\"data row11 col11\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col12\" class=\"data row11 col12\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow11_col13\" class=\"data row11 col13\" >0.00044</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row12\" class=\"row_heading level0 row12\" >dropoff_latitude</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col0\" class=\"data row12 col0\" >-0.00041</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col1\" class=\"data row12 col1\" >-0.0033</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col2\" class=\"data row12 col2\" >0.001</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col3\" class=\"data row12 col3\" >0.00088</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col4\" class=\"data row12 col4\" >-0.00042</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col5\" class=\"data row12 col5\" >-0.00076</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col6\" class=\"data row12 col6\" >0.0018</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col7\" class=\"data row12 col7\" >0.0028</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col8\" class=\"data row12 col8\" >0.00046</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col9\" class=\"data row12 col9\" >-0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col10\" class=\"data row12 col10\" >0.96</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col11\" class=\"data row12 col11\" >-1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col12\" class=\"data row12 col12\" >1</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow12_col13\" class=\"data row12 col13\" >-0.0004</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4flevel0_row13\" class=\"row_heading level0 row13\" >target</th>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col0\" class=\"data row13 col0\" >-0.091</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col1\" class=\"data row13 col1\" >-0.02</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col2\" class=\"data row13 col2\" >0.014</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col3\" class=\"data row13 col3\" >-0.049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col4\" class=\"data row13 col4\" >-0.19</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col5\" class=\"data row13 col5\" >-0.00071</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col6\" class=\"data row13 col6\" >-0.002</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col7\" class=\"data row13 col7\" >-0.0015</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col8\" class=\"data row13 col8\" >-0.0021</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col9\" class=\"data row13 col9\" >0.00049</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col10\" class=\"data row13 col10\" >-0.00045</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col11\" class=\"data row13 col11\" >0.00044</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col12\" class=\"data row13 col12\" >-0.0004</td>\n                        <td id=\"T_c04289b6_c41f_11eb_93f5_00163ee26a4frow13_col13\" class=\"data row13 col13\" >1</td>\n            </tr>\n    </tbody></table>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Write the data to disk, as a parquet file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fde21909-541f-43b1-bd56-3c0034b4bbe6"}}},{"cell_type":"code","source":["nyc_flattened_data.reset_index().to_parquet(\"dbfs:/databricks/datasets/nycfull/nyc_joined_with_targets.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efc282f3-990e-4fba-9795-b608484d080b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# AutoML Experiment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ba5f51b-d610-474e-9054-9d5c8ab26ae1"}}},{"cell_type":"code","source":["import pandas as pd\n\nfrom azureml.core import Dataset, Experiment, Workspace\nfrom azureml.train.automl import AutoMLConfig\n\nws_name = \"gasi_ws_eastus2\"\nrg_name = \"gasi_rg_eastus2\"\nsubscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\"\nexperiment_name = \"sparkfhl\"\n\nworkspace = Workspace(workspace_name=ws_name, resource_group=rg_name, subscription_id=subscription_id)\nexperiment = Experiment(workspace=workspace, name=experiment_name)\n\noutput = {}\noutput['Subscription ID'] = workspace.subscription_id\noutput['Workspace'] = workspace.name\noutput['Resource Group'] = workspace.resource_group\noutput['Location'] = workspace.location\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\noutputDf = pd.DataFrame(data = output, index = [''])\noutputDf.T"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"984121f4-d818-4ff0-a951-2a9810f53b14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Subscription ID</th>\n      <td>381b38e9-9840-4719-a5a0-61d9585e1e91</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>gasi_ws_eastus2</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>gasi_rg_eastus2</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>eastus2</td>\n    </tr>\n    <tr>\n      <th>Experiment Name</th>\n      <td>sparkfhl</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F2C7G8KPV to authenticate.\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nOut[3]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Subscription ID</th>\n      <td>381b38e9-9840-4719-a5a0-61d9585e1e91</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>gasi_ws_eastus2</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>gasi_rg_eastus2</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>eastus2</td>\n    </tr>\n    <tr>\n      <th>Experiment Name</th>\n      <td>sparkfhl</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["target_column = \"target\"\n\nspark_settings = {\n        \"spark_context\": sc,\n        \"allowed_models\": [\"LightGBM\", \"LogisticRegression\", \"RandomForest\"],\n}\n\nautoml_settings = {\n        \"experiment_timeout_hours\": 24,\n        \"primary_metric\": \"accuracy\",\n        \"validation_size\": 0.01,\n        \"save_mlflow\": True,\n        \"iterations\": 20,\n        \"enable_stack_ensemble\": False,\n        \"enable_voting_ensemble\": False,\n}\n\nautoml_config = AutoMLConfig(\n  task=\"classification\",\n  training_data=nyc_flattened_data,\n  label_column_name=target_column,\n  model_explainability=False,\n  **automl_settings,\n  **spark_settings,\n)\n\nautoml_config"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2fb5edb-0ee3-497b-93f2-f8b936fd6491"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">WARNING:root:save_mlflow is an internal parameter that should not be used for regular experiments.\nOut[5]: &lt;azureml.train.automl.automlconfig.AutoMLConfig at 0x7f4f6fa4e9d0&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:root:save_mlflow is an internal parameter that should not be used for regular experiments.\nOut[5]: &lt;azureml.train.automl.automlconfig.AutoMLConfig at 0x7f4f6fa4e9d0&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["run = experiment.submit(automl_config, show_output=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85370f0e-2e08-4c9e-b0b1-c47fc101c49c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Submitting spark run.\nNo run_configuration provided, running on local with default configuration\n&lt;IPython.core.display.HTML object&gt;\nRunning an experiment on spark cluster: sparkfhl.\n\nDebug logs are being sent to /databricks/driver/azureml.log\nValidation data shape:  (32206, 22)\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:05:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_0, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:10:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_1, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:14:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_2, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:19:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_3, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:23:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_4, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:37:59 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_5, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\nTraceback (most recent call last):\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/train/automl/runtime/_entrypoints/spark/worker_node.py&#34;, line 564, in execute_pipeline\n    pipeline_dto, run_id)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/train/automl/runtime/_entrypoints/spark/worker_node.py&#34;, line 494, in _train_iteration\n    raise exception_obj.with_traceback(exception_obj.__traceback__)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/fit_pipeline.py&#34;, line 135, in fit_pipeline\n    telemetry_logger,\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/fit_pipeline.py&#34;, line 242, in _fit_pipeline_internal\n    control_settings, resource_settings, automl_pipeline, automl_run_context, iteration_timeout_min\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/pipeline_run_helper.py&#34;, line 329, in run_pipeline\n    raise PipelineRunException.from_exception(status)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/resource_limits.py&#34;, line 109, in wrapped\n    result = func(*args, **kwargs)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/runner.py&#34;, line 337, in _run\n    pipeline_spec, problem_info, random_state=random_state)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/runner.py&#34;, line 96, in _run_train_valid\n    weight_column_name))\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/_ml_engine/training/train.py&#34;, line 33, in train\n    return fit_spark_pipeline(pipeline, training_data)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/_ml_engine/training/train.py&#34;, line 56, in fit_spark_pipeline\n    pipeline_model = pipeline.fit(training_data.data.to_spark())\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/pipeline.py&#34;, line 109, in _fit\n    model = stage.fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/pipeline.py&#34;, line 109, in _fit\n    model = stage.fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/local_disk0/spark-9b6d6dda-e0c4-4623-b879-94045f04d226/userFiles-1964ca29-5477-484a-8a0b-06c58770ea63/addedFile7861837766543815559mmlspark_2_12_1_0_0_rc3_62_25d40cff_SNAPSHOT-e9cdd.jar/mmlspark/lightgbm/LightGBMClassifier.py&#34;, line 1228, in _fit\n    java_model = self._fit_java(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/wrapper.py&#34;, line 318, in _fit_java\n    return self._java_obj.fit(dataset._jdf)\n  File &#34;/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&#34;, line 1305, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File &#34;/databricks/spark/python/pyspark/sql/utils.py&#34;, line 127, in deco\n    return f(*a, **kw)\n  File &#34;/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py&#34;, line 328, in get_return_value\n    format(target_id, &#34;.&#34;, name), value)\nazureml.automl.core.shared.exceptions.PipelineRunException: PipelineRunException:\n\tMessage: PipelineRunException: An error occurred while calling o14483.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 689.0 failed 4 times, most recent failure: Lost task 22.3 in stage 689.0 (TID 8725, 10.139.64.8, executor 3): java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\n\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\n\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n\n\tInnerException: Py4JJavaError: An error occurred while calling o14483.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 689.0 failed 4 times, most recent failure: Lost task 22.3 in stage 689.0 (TID 8725, 10.139.64.8, executor 3): java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\n\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\n\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\n*** WARNING: skipped 49501 bytes of output ***\n\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n\n\tErrorResponse \n{\n    &#34;error&#34;: {\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o21224.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 998.0 failed 4 times, most recent failure: Lost task 35.3 in stage 998.0 (TID 11540, 10.139.64.8, executor 6): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\t... 1 more\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o21224.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 998.0 failed 4 times, most recent failure: Lost task 35.3 in stage 998.0 (TID 11540, 10.139.64.8, executor 6): java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\t... 1 more\\\\n\\&#34;\\n    }\\n}&#34;,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;inner_error&#34;: {\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;code&#34;: &#34;AutoMLInternal&#34;\n            }\n        }\n    }\n}\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Submitting spark run.\nNo run_configuration provided, running on local with default configuration\n&lt;IPython.core.display.HTML object&gt;\nRunning an experiment on spark cluster: sparkfhl.\n\nDebug logs are being sent to /databricks/driver/azureml.log\nValidation data shape:  (32206, 22)\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:05:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_0, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:10:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_1, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:14:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_2, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:19:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_3, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:23:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_4, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n2021/06/03 06:37:59 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AutoML_31d1999b-6380-4013-98e1-66342728b152_5, version 1\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\nTraceback (most recent call last):\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/train/automl/runtime/_entrypoints/spark/worker_node.py&#34;, line 564, in execute_pipeline\n    pipeline_dto, run_id)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/train/automl/runtime/_entrypoints/spark/worker_node.py&#34;, line 494, in _train_iteration\n    raise exception_obj.with_traceback(exception_obj.__traceback__)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/fit_pipeline.py&#34;, line 135, in fit_pipeline\n    telemetry_logger,\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/fit_pipeline.py&#34;, line 242, in _fit_pipeline_internal\n    control_settings, resource_settings, automl_pipeline, automl_run_context, iteration_timeout_min\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/pipeline_run_helper.py&#34;, line 329, in run_pipeline\n    raise PipelineRunException.from_exception(status)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/resource_limits.py&#34;, line 109, in wrapped\n    result = func(*args, **kwargs)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/runner.py&#34;, line 337, in _run\n    pipeline_spec, problem_info, random_state=random_state)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/shared/runner.py&#34;, line 96, in _run_train_valid\n    weight_column_name))\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/_ml_engine/training/train.py&#34;, line 33, in train\n    return fit_spark_pipeline(pipeline, training_data)\n  File &#34;/databricks/python/lib/python3.7/site-packages/azureml/automl/runtime/_ml_engine/training/train.py&#34;, line 56, in fit_spark_pipeline\n    pipeline_model = pipeline.fit(training_data.data.to_spark())\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/pipeline.py&#34;, line 109, in _fit\n    model = stage.fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/pipeline.py&#34;, line 109, in _fit\n    model = stage.fit(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/base.py&#34;, line 129, in fit\n    return self._fit(dataset)\n  File &#34;/local_disk0/spark-9b6d6dda-e0c4-4623-b879-94045f04d226/userFiles-1964ca29-5477-484a-8a0b-06c58770ea63/addedFile7861837766543815559mmlspark_2_12_1_0_0_rc3_62_25d40cff_SNAPSHOT-e9cdd.jar/mmlspark/lightgbm/LightGBMClassifier.py&#34;, line 1228, in _fit\n    java_model = self._fit_java(dataset)\n  File &#34;/databricks/spark/python/pyspark/ml/wrapper.py&#34;, line 318, in _fit_java\n    return self._java_obj.fit(dataset._jdf)\n  File &#34;/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&#34;, line 1305, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File &#34;/databricks/spark/python/pyspark/sql/utils.py&#34;, line 127, in deco\n    return f(*a, **kw)\n  File &#34;/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py&#34;, line 328, in get_return_value\n    format(target_id, &#34;.&#34;, name), value)\nazureml.automl.core.shared.exceptions.PipelineRunException: PipelineRunException:\n\tMessage: PipelineRunException: An error occurred while calling o14483.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 689.0 failed 4 times, most recent failure: Lost task 22.3 in stage 689.0 (TID 8725, 10.139.64.8, executor 3): java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\n\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\n\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n\n\tInnerException: Py4JJavaError: An error occurred while calling o14483.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 689.0 failed 4 times, most recent failure: Lost task 22.3 in stage 689.0 (TID 8725, 10.139.64.8, executor 3): java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\n\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\n\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\n\n*** WARNING: skipped 49501 bytes of output ***\n\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\n\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\n\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n\n\tErrorResponse \n{\n    &#34;error&#34;: {\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o21224.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 998.0 failed 4 times, most recent failure: Lost task 35.3 in stage 998.0 (TID 11540, 10.139.64.8, executor 6): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\t... 1 more\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o21224.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 998.0 failed 4 times, most recent failure: Lost task 35.3 in stage 998.0 (TID 11540, 10.139.64.8, executor 6): java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\t... 1 more\\\\n\\&#34;\\n    }\\n}&#34;,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;inner_error&#34;: {\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;code&#34;: &#34;AutoMLInternal&#34;\n            }\n        }\n    }\n}\nDisabling log capture. Resulting file is at /databricks/driver/azureml.log\nDebug logs are being sent to /databricks/driver/azureml.log\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["run.wait_for_completion(show_output=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5859767-5d4a-4e3e-bd8d-1a7d954e179b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n\n\n****************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n****************************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   MaxAbsScaler LightGBMClassifier                0:00:49       0.9918    0.9918\n         1   MinMaxScaler RandomForestClassifier            0:03:03       0.9853    0.9918\n         2   MinMaxScaler RandomForestClassifier            0:03:08       0.9851    0.9918\n         3   MinMaxScaler RandomForestClassifier            0:03:02       0.9853    0.9918\n         4   MinMaxScaler RandomForestClassifier            0:03:05       0.9851    0.9918\n         5   Normalizer LogisticRegression                  0:00:53       0.5057    0.9918\n         6   RobustScaler RandomForestClassifier            0:10:00       0.9853    0.9918\n         7   MinMaxScaler LightGBMClassifier                0:01:22       0.9877    0.9918\n         8   RobustScaler LightGBMClassifier                0:11:03          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o34974.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.ap&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;PipelineRunException&#34;,\n            &#34;error_details&#34;: &#34;PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o34974.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\t... 1 more\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o34974.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\t... 1 more\\\\n\\&#34;\\n    }\\n}&#34;\n\n*** WARNING: skipped 53324 bytes of output ***\n\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        13   MinMaxScaler RandomForestClassifier            0:02:36       0.9879    0.9918\n        14   StandardScaler LightGBMClassifier              0:00:41       0.9907    0.9918\n        15   MaxAbsScaler LightGBMClassifier                0:00:41       0.6220    0.9918\n        16   RobustScaler LightGBMClassifier                0:11:24          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o44605.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecutio&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;PipelineRunException&#34;,\n            &#34;error_details&#34;: &#34;PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o44605.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.GeneratedMethodAccessor749.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o44605.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.GeneratedMethodAccessor749.invoke(Unknown Source)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\&#34;\\n    }\\n}&#34;\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        17   MinMaxScaler LightGBMClassifier                0:01:39       0.9906    0.9918\n        18                                                  0:00:01          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: ClientException. Additional Info: ClientException:\\n\\tMessage: &#39;TruncatedSVDWrapper&#39;\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;&#39;TruncatedSVDWrapper&#39;\\&#34;\\n    }\\n}&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: ClientException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;ClientException&#34;,\n            &#34;error_details&#34;: &#34;ClientException:\\n\\tMessage: &#39;TruncatedSVDWrapper&#39;\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;&#39;TruncatedSVDWrapper&#39;\\&#34;\\n    }\\n}&#34;\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        19   MaxAbsScaler LightGBMClassifier                0:00:40       0.9896    0.9918\nOut[49]: {&#39;runId&#39;: &#39;AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f&#39;,\n &#39;target&#39;: &#39;local&#39;,\n &#39;status&#39;: &#39;Completed&#39;,\n &#39;startTimeUtc&#39;: &#39;2021-06-03T04:21:03.987821Z&#39;,\n &#39;endTimeUtc&#39;: &#39;2021-06-03T05:25:47.710904Z&#39;,\n &#39;properties&#39;: {&#39;num_iterations&#39;: &#39;20&#39;,\n  &#39;training_type&#39;: &#39;TrainFull&#39;,\n  &#39;acquisition_function&#39;: &#39;EI&#39;,\n  &#39;primary_metric&#39;: &#39;accuracy&#39;,\n  &#39;train_split&#39;: &#39;0.01&#39;,\n  &#39;acquisition_parameter&#39;: &#39;0&#39;,\n  &#39;num_cross_validation&#39;: None,\n  &#39;target&#39;: &#39;local&#39;,\n  &#39;AMLSettingsJsonString&#39;: &#39;{&#34;path&#34;:null,&#34;name&#34;:&#34;sparkfhl&#34;,&#34;subscription_id&#34;:&#34;381b38e9-9840-4719-a5a0-61d9585e1e91&#34;,&#34;resource_group&#34;:&#34;gasi_rg_eastus2&#34;,&#34;workspace_name&#34;:&#34;gasi_ws_eastus2&#34;,&#34;region&#34;:&#34;eastus2&#34;,&#34;compute_target&#34;:&#34;local&#34;,&#34;spark_service&#34;:&#34;adb&#34;,&#34;azure_service&#34;:&#34;Microsoft.AzureDataBricks&#34;,&#34;many_models&#34;:false,&#34;pipeline_fetch_max_batch_size&#34;:1,&#34;enable_batch_run&#34;:false,&#34;enable_run_restructure&#34;:false,&#34;start_auxiliary_runs_before_parent_complete&#34;:false,&#34;enable_code_generation&#34;:false,&#34;iterations&#34;:20,&#34;primary_metric&#34;:&#34;accuracy&#34;,&#34;task_type&#34;:&#34;classification&#34;,&#34;data_script&#34;:null,&#34;test_size&#34;:0.0,&#34;validation_size&#34;:0.01,&#34;n_cross_validations&#34;:null,&#34;y_min&#34;:null,&#34;y_max&#34;:null,&#34;num_classes&#34;:null,&#34;featurization&#34;:&#34;auto&#34;,&#34;_ignore_package_version_incompatibilities&#34;:false,&#34;is_timeseries&#34;:false,&#34;max_cores_per_iteration&#34;:1,&#34;max_concurrent_iterations&#34;:1,&#34;iteration_timeout_minutes&#34;:null,&#34;mem_in_mb&#34;:null,&#34;enforce_time_on_windows&#34;:false,&#34;experiment_timeout_minutes&#34;:1440,&#34;experiment_exit_score&#34;:null,&#34;whitelist_models&#34;:[&#34;LogisticRegression&#34;,&#34;RandomForest&#34;,&#34;LightGBM&#34;],&#34;blacklist_algos&#34;:[&#34;TensorFlowLinearClassifier&#34;,&#34;TensorFlowDNN&#34;],&#34;supported_models&#34;:[&#34;SVM&#34;,&#34;TensorFlowDNN&#34;,&#34;SGD&#34;,&#34;RandomForest&#34;,&#34;XGBoostClassifier&#34;,&#34;BernoulliNaiveBayes&#34;,&#34;KNN&#34;,&#34;LogisticRegression&#34;,&#34;GradientBoosting&#34;,&#34;TensorFlowLinearClassifier&#34;,&#34;MultinomialNaiveBayes&#34;,&#34;LinearSVM&#34;,&#34;AveragedPerceptronClassifier&#34;,&#34;DecisionTree&#34;,&#34;ExtremeRandomTrees&#34;,&#34;LightGBM&#34;],&#34;private_models&#34;:[],&#34;auto_blacklist&#34;:true,&#34;blacklist_samples_reached&#34;:false,&#34;exclude_nan_labels&#34;:true,&#34;verbosity&#34;:20,&#34;_debug_log&#34;:&#34;automl.log&#34;,&#34;show_warnings&#34;:false,&#34;model_explainability&#34;:false,&#34;service_url&#34;:null,&#34;sdk_url&#34;:null,&#34;sdk_packages&#34;:null,&#34;enable_onnx_compatible_models&#34;:false,&#34;enable_split_onnx_featurizer_estimator_models&#34;:false,&#34;vm_type&#34;:null,&#34;telemetry_verbosity&#34;:20,&#34;send_telemetry&#34;:true,&#34;enable_dnn&#34;:false,&#34;scenario&#34;:&#34;non-prod&#34;,&#34;environment_label&#34;:null,&#34;save_mlflow&#34;:false,&#34;force_text_dnn&#34;:false,&#34;enable_feature_sweeping&#34;:true,&#34;enable_early_stopping&#34;:false,&#34;early_stopping_n_iters&#34;:10,&#34;metrics&#34;:null,&#34;enable_metric_confidence&#34;:false,&#34;enable_ensembling&#34;:false,&#34;enable_stack_ensembling&#34;:false,&#34;ensemble_iterations&#34;:15,&#34;enable_tf&#34;:false,&#34;enable_subsampling&#34;:false,&#34;subsample_seed&#34;:null,&#34;enable_nimbusml&#34;:false,&#34;enable_streaming&#34;:false,&#34;force_streaming&#34;:false,&#34;track_child_runs&#34;:true,&#34;allowed_private_models&#34;:[],&#34;label_column_name&#34;:&#34;target&#34;,&#34;weight_column_name&#34;:null,&#34;cv_split_column_names&#34;:null,&#34;enable_local_managed&#34;:false,&#34;_local_managed_run_id&#34;:null,&#34;cost_mode&#34;:1,&#34;lag_length&#34;:0,&#34;metric_operation&#34;:&#34;maximize&#34;,&#34;preprocess&#34;:true}&#39;,\n  &#39;DataPrepJsonString&#39;: None,\n  &#39;EnableSubsampling&#39;: &#39;False&#39;,\n  &#39;runTemplate&#39;: &#39;AutoML&#39;,\n  &#39;azureml.runsource&#39;: &#39;automl&#39;,\n  &#39;display_task_type&#39;: &#39;classification&#39;,\n  &#39;dependencies_versions&#39;: &#39;{&#34;azureml-train&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-restclients-hyperdrive&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl-client&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-telemetry&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-sdk&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline-steps&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-model-management-sdk&#34;: &#34;1.0.1b6.post1&#34;, &#34;azureml-interpret&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-defaults&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-dataset-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-dataprep&#34;: &#34;2.15.1&#34;, &#34;azureml-dataprep-rslex&#34;: &#34;1.13.0&#34;, &#34;azureml-dataprep-native&#34;: &#34;33.0.0&#34;, &#34;azureml-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-automl-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-automl-core&#34;: &#34;0.1.0.39032837&#34;}&#39;,\n  &#39;_aml_system_scenario_identification&#39;: &#39;ADB.Parent&#39;,\n  &#39;ClientSdkVersion&#39;: &#39;0.1.0.39032837&#39;,\n  &#39;ClientType&#39;: &#39;SDK&#39;,\n  &#39;environment_cpu_name&#39;: &#39;AutoML-Non-Prod&#39;,\n  &#39;environment_cpu_label&#39;: &#39;Latest&#39;,\n  &#39;environment_gpu_name&#39;: &#39;AutoML-Non-Prod-GPU&#39;,\n  &#39;environment_gpu_label&#39;: &#39;Latest&#39;,\n  &#39;root_attribution&#39;: &#39;automl&#39;,\n  &#39;attribution&#39;: &#39;AutoML&#39;,\n  &#39;Orchestrator&#39;: &#39;AutoML&#39;,\n  &#39;CancelUri&#39;: &#39;https://eastus2.api.azureml.ms/jasmine/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_eastus2/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_eastus2/experimentids/ad749000-ecd4-4a85-91c1-26ebf9f36aef/cancel/AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f&#39;,\n  &#39;_azureml.ComputeTargetType&#39;: &#39;local&#39;,\n  &#39;snapshotId&#39;: &#39;00000000-0000-0000-0000-000000000000&#39;,\n  &#39;SetupRunId&#39;: &#39;AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f_setup&#39;,\n  &#39;SetupRunContainerId&#39;: &#39;dcid.AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f_setup&#39;,\n  &#39;ProblemInfoJsonString&#39;: &#39;{&#34;dataset_num_categorical&#34;: 0, &#34;is_sparse&#34;: false, &#34;subsampling&#34;: false, &#34;has_extra_col&#34;: true, &#34;dataset_features&#34;: 21}&#39;},\n &#39;outputDatasets&#39;: [],\n &#39;logFiles&#39;: {},\n &#39;submittedBy&#39;: &#39;Gaurav Singh&#39;}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n\n\n****************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n****************************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   MaxAbsScaler LightGBMClassifier                0:00:49       0.9918    0.9918\n         1   MinMaxScaler RandomForestClassifier            0:03:03       0.9853    0.9918\n         2   MinMaxScaler RandomForestClassifier            0:03:08       0.9851    0.9918\n         3   MinMaxScaler RandomForestClassifier            0:03:02       0.9853    0.9918\n         4   MinMaxScaler RandomForestClassifier            0:03:05       0.9851    0.9918\n         5   Normalizer LogisticRegression                  0:00:53       0.5057    0.9918\n         6   RobustScaler RandomForestClassifier            0:10:00       0.9853    0.9918\n         7   MinMaxScaler LightGBMClassifier                0:01:22       0.9877    0.9918\n         8   RobustScaler LightGBMClassifier                0:11:03          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o34974.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.ap&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;PipelineRunException&#34;,\n            &#34;error_details&#34;: &#34;PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o34974.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\n\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\n\\tat java.net.Socket.connect(Socket.java:607)\\n\\tat java.net.Socket.connect(Socket.java:556)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\n\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\n\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\n\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\n\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\t... 1 more\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o34974.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 54 in stage 1280.0 failed 4 times, most recent failure: Lost task 54.3 in stage 1280.0 (TID 27273, 10.139.64.8, executor 7): java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\\\n\\\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\\\\n\\\\tat java.net.PlainSocketImpl.socketConnect(Native Method)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\\\\n\\\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\\\\n\\\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\\\n\\\\tat java.net.Socket.connect(Socket.java:607)\\\\n\\\\tat java.net.Socket.connect(Socket.java:556)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\\\\n\\\\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:556)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$2(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:52)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.downloader.FaultToleranceUtils$.retryWithTimeout(ModelDownloader.scala:57)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.$anonfun$trainLightGBM$1(TrainUtils.scala:650)\\\\n\\\\tat com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:29)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:644)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.$anonfun$innerTrain$3(LightGBMBase.scala:225)\\\\n\\\\tat org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:222)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:879)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\\\\n\\\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:356)\\\\n\\\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:320)\\\\n\\\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\\\n\\\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\\\\n\\\\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:640)\\\\n\\\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\\\\n\\\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\t... 1 more\\\\n\\&#34;\\n    }\\n}&#34;\n\n*** WARNING: skipped 53324 bytes of output ***\n\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        13   MinMaxScaler RandomForestClassifier            0:02:36       0.9879    0.9918\n        14   StandardScaler LightGBMClassifier              0:00:41       0.9907    0.9918\n        15   MaxAbsScaler LightGBMClassifier                0:00:41       0.6220    0.9918\n        16   RobustScaler LightGBMClassifier                0:11:24          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o44605.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecutio&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;PipelineRunException&#34;,\n            &#34;error_details&#34;: &#34;PipelineRunException:\\n\\tMessage: PipelineRunException: An error occurred while calling o44605.fit.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\n\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\n\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\n\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\n\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\n\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\n\\tat sun.reflect.GeneratedMethodAccessor749.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\n\\tat py4j.Gateway.invoke(Gateway.java:295)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;PipelineRunException: An error occurred while calling o44605.fit.\\\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 1683.0 failed 4 times, most recent failure: Lost task 57.3 in stage 1683.0 (TID 34585, 10.139.64.8, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\\\\nDriver stacktrace:\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\\\n\\\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\\\\n\\\\tat scala.Option.foreach(Option.scala:407)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\\\\n\\\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\\\\n\\\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\\\n\\\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\\\\n\\\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2434)\\\\n\\\\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1101)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\\\\n\\\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\\\n\\\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:395)\\\\n\\\\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1083)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1761)\\\\n\\\\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3698)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\\\\n\\\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\\\\n\\\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\\\\n\\\\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3696)\\\\n\\\\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1761)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain(LightGBMBase.scala:230)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.innerTrain$(LightGBMBase.scala:187)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.innerTrain(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train(LightGBMBase.scala:48)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMBase.train$(LightGBMBase.scala:28)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat com.microsoft.ml.spark.lightgbm.LightGBMClassifier.train(LightGBMClassifier.scala:22)\\\\n\\\\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\\\\n\\\\tat sun.reflect.GeneratedMethodAccessor749.invoke(Unknown Source)\\\\n\\\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\\\\tat java.lang.reflect.Method.invoke(Method.java:498)\\\\n\\\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\\\n\\\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\\\\n\\\\tat py4j.Gateway.invoke(Gateway.java:295)\\\\n\\\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\\\n\\\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\\\n\\\\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\&#34;\\n    }\\n}&#34;\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        17   MinMaxScaler LightGBMClassifier                0:01:39       0.9906    0.9918\n        18                                                  0:00:01          nan    0.9918\nERROR: {\n    &#34;additional_properties&#34;: {},\n    &#34;error&#34;: {\n        &#34;additional_properties&#34;: {\n            &#34;debugInfo&#34;: null\n        },\n        &#34;code&#34;: &#34;SystemError&#34;,\n        &#34;severity&#34;: null,\n        &#34;message&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: ClientException. Additional Info: ClientException:\\n\\tMessage: &#39;TruncatedSVDWrapper&#39;\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;&#39;TruncatedSVDWrapper&#39;\\&#34;\\n    }\\n}&#34;,\n        &#34;message_format&#34;: &#34;Encountered an internal AutoML error. Error Message/Code: ClientException. Additional Info: {error_details}&#34;,\n        &#34;message_parameters&#34;: {\n            &#34;error_message&#34;: &#34;ClientException&#34;,\n            &#34;error_details&#34;: &#34;ClientException:\\n\\tMessage: &#39;TruncatedSVDWrapper&#39;\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&#34;error\\&#34;: {\\n        \\&#34;message\\&#34;: \\&#34;&#39;TruncatedSVDWrapper&#39;\\&#34;\\n    }\\n}&#34;\n        },\n        &#34;reference_code&#34;: null,\n        &#34;details_uri&#34;: &#34;https://docs.microsoft.com/azure/machine-learning/resource-known-issues#automated-machine-learning&#34;,\n        &#34;target&#34;: null,\n        &#34;details&#34;: [],\n        &#34;inner_error&#34;: {\n            &#34;additional_properties&#34;: {},\n            &#34;code&#34;: &#34;ClientError&#34;,\n            &#34;inner_error&#34;: {\n                &#34;additional_properties&#34;: {},\n                &#34;code&#34;: &#34;AutoMLInternal&#34;,\n                &#34;inner_error&#34;: null\n            }\n        },\n        &#34;additional_info&#34;: null\n    },\n    &#34;correlation&#34;: null,\n    &#34;environment&#34;: null,\n    &#34;location&#34;: null,\n    &#34;time&#34;: {},\n    &#34;component_name&#34;: null\n}\n        19   MaxAbsScaler LightGBMClassifier                0:00:40       0.9896    0.9918\nOut[49]: {&#39;runId&#39;: &#39;AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f&#39;,\n &#39;target&#39;: &#39;local&#39;,\n &#39;status&#39;: &#39;Completed&#39;,\n &#39;startTimeUtc&#39;: &#39;2021-06-03T04:21:03.987821Z&#39;,\n &#39;endTimeUtc&#39;: &#39;2021-06-03T05:25:47.710904Z&#39;,\n &#39;properties&#39;: {&#39;num_iterations&#39;: &#39;20&#39;,\n  &#39;training_type&#39;: &#39;TrainFull&#39;,\n  &#39;acquisition_function&#39;: &#39;EI&#39;,\n  &#39;primary_metric&#39;: &#39;accuracy&#39;,\n  &#39;train_split&#39;: &#39;0.01&#39;,\n  &#39;acquisition_parameter&#39;: &#39;0&#39;,\n  &#39;num_cross_validation&#39;: None,\n  &#39;target&#39;: &#39;local&#39;,\n  &#39;AMLSettingsJsonString&#39;: &#39;{&#34;path&#34;:null,&#34;name&#34;:&#34;sparkfhl&#34;,&#34;subscription_id&#34;:&#34;381b38e9-9840-4719-a5a0-61d9585e1e91&#34;,&#34;resource_group&#34;:&#34;gasi_rg_eastus2&#34;,&#34;workspace_name&#34;:&#34;gasi_ws_eastus2&#34;,&#34;region&#34;:&#34;eastus2&#34;,&#34;compute_target&#34;:&#34;local&#34;,&#34;spark_service&#34;:&#34;adb&#34;,&#34;azure_service&#34;:&#34;Microsoft.AzureDataBricks&#34;,&#34;many_models&#34;:false,&#34;pipeline_fetch_max_batch_size&#34;:1,&#34;enable_batch_run&#34;:false,&#34;enable_run_restructure&#34;:false,&#34;start_auxiliary_runs_before_parent_complete&#34;:false,&#34;enable_code_generation&#34;:false,&#34;iterations&#34;:20,&#34;primary_metric&#34;:&#34;accuracy&#34;,&#34;task_type&#34;:&#34;classification&#34;,&#34;data_script&#34;:null,&#34;test_size&#34;:0.0,&#34;validation_size&#34;:0.01,&#34;n_cross_validations&#34;:null,&#34;y_min&#34;:null,&#34;y_max&#34;:null,&#34;num_classes&#34;:null,&#34;featurization&#34;:&#34;auto&#34;,&#34;_ignore_package_version_incompatibilities&#34;:false,&#34;is_timeseries&#34;:false,&#34;max_cores_per_iteration&#34;:1,&#34;max_concurrent_iterations&#34;:1,&#34;iteration_timeout_minutes&#34;:null,&#34;mem_in_mb&#34;:null,&#34;enforce_time_on_windows&#34;:false,&#34;experiment_timeout_minutes&#34;:1440,&#34;experiment_exit_score&#34;:null,&#34;whitelist_models&#34;:[&#34;LogisticRegression&#34;,&#34;RandomForest&#34;,&#34;LightGBM&#34;],&#34;blacklist_algos&#34;:[&#34;TensorFlowLinearClassifier&#34;,&#34;TensorFlowDNN&#34;],&#34;supported_models&#34;:[&#34;SVM&#34;,&#34;TensorFlowDNN&#34;,&#34;SGD&#34;,&#34;RandomForest&#34;,&#34;XGBoostClassifier&#34;,&#34;BernoulliNaiveBayes&#34;,&#34;KNN&#34;,&#34;LogisticRegression&#34;,&#34;GradientBoosting&#34;,&#34;TensorFlowLinearClassifier&#34;,&#34;MultinomialNaiveBayes&#34;,&#34;LinearSVM&#34;,&#34;AveragedPerceptronClassifier&#34;,&#34;DecisionTree&#34;,&#34;ExtremeRandomTrees&#34;,&#34;LightGBM&#34;],&#34;private_models&#34;:[],&#34;auto_blacklist&#34;:true,&#34;blacklist_samples_reached&#34;:false,&#34;exclude_nan_labels&#34;:true,&#34;verbosity&#34;:20,&#34;_debug_log&#34;:&#34;automl.log&#34;,&#34;show_warnings&#34;:false,&#34;model_explainability&#34;:false,&#34;service_url&#34;:null,&#34;sdk_url&#34;:null,&#34;sdk_packages&#34;:null,&#34;enable_onnx_compatible_models&#34;:false,&#34;enable_split_onnx_featurizer_estimator_models&#34;:false,&#34;vm_type&#34;:null,&#34;telemetry_verbosity&#34;:20,&#34;send_telemetry&#34;:true,&#34;enable_dnn&#34;:false,&#34;scenario&#34;:&#34;non-prod&#34;,&#34;environment_label&#34;:null,&#34;save_mlflow&#34;:false,&#34;force_text_dnn&#34;:false,&#34;enable_feature_sweeping&#34;:true,&#34;enable_early_stopping&#34;:false,&#34;early_stopping_n_iters&#34;:10,&#34;metrics&#34;:null,&#34;enable_metric_confidence&#34;:false,&#34;enable_ensembling&#34;:false,&#34;enable_stack_ensembling&#34;:false,&#34;ensemble_iterations&#34;:15,&#34;enable_tf&#34;:false,&#34;enable_subsampling&#34;:false,&#34;subsample_seed&#34;:null,&#34;enable_nimbusml&#34;:false,&#34;enable_streaming&#34;:false,&#34;force_streaming&#34;:false,&#34;track_child_runs&#34;:true,&#34;allowed_private_models&#34;:[],&#34;label_column_name&#34;:&#34;target&#34;,&#34;weight_column_name&#34;:null,&#34;cv_split_column_names&#34;:null,&#34;enable_local_managed&#34;:false,&#34;_local_managed_run_id&#34;:null,&#34;cost_mode&#34;:1,&#34;lag_length&#34;:0,&#34;metric_operation&#34;:&#34;maximize&#34;,&#34;preprocess&#34;:true}&#39;,\n  &#39;DataPrepJsonString&#39;: None,\n  &#39;EnableSubsampling&#39;: &#39;False&#39;,\n  &#39;runTemplate&#39;: &#39;AutoML&#39;,\n  &#39;azureml.runsource&#39;: &#39;automl&#39;,\n  &#39;display_task_type&#39;: &#39;classification&#39;,\n  &#39;dependencies_versions&#39;: &#39;{&#34;azureml-train&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-restclients-hyperdrive&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-train-automl-client&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-telemetry&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-sdk&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline-steps&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-pipeline-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-model-management-sdk&#34;: &#34;1.0.1b6.post1&#34;, &#34;azureml-interpret&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-defaults&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-dataset-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-dataprep&#34;: &#34;2.15.1&#34;, &#34;azureml-dataprep-rslex&#34;: &#34;1.13.0&#34;, &#34;azureml-dataprep-native&#34;: &#34;33.0.0&#34;, &#34;azureml-core&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-automl-runtime&#34;: &#34;0.1.0.39032837&#34;, &#34;azureml-automl-core&#34;: &#34;0.1.0.39032837&#34;}&#39;,\n  &#39;_aml_system_scenario_identification&#39;: &#39;ADB.Parent&#39;,\n  &#39;ClientSdkVersion&#39;: &#39;0.1.0.39032837&#39;,\n  &#39;ClientType&#39;: &#39;SDK&#39;,\n  &#39;environment_cpu_name&#39;: &#39;AutoML-Non-Prod&#39;,\n  &#39;environment_cpu_label&#39;: &#39;Latest&#39;,\n  &#39;environment_gpu_name&#39;: &#39;AutoML-Non-Prod-GPU&#39;,\n  &#39;environment_gpu_label&#39;: &#39;Latest&#39;,\n  &#39;root_attribution&#39;: &#39;automl&#39;,\n  &#39;attribution&#39;: &#39;AutoML&#39;,\n  &#39;Orchestrator&#39;: &#39;AutoML&#39;,\n  &#39;CancelUri&#39;: &#39;https://eastus2.api.azureml.ms/jasmine/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_eastus2/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_eastus2/experimentids/ad749000-ecd4-4a85-91c1-26ebf9f36aef/cancel/AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f&#39;,\n  &#39;_azureml.ComputeTargetType&#39;: &#39;local&#39;,\n  &#39;snapshotId&#39;: &#39;00000000-0000-0000-0000-000000000000&#39;,\n  &#39;SetupRunId&#39;: &#39;AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f_setup&#39;,\n  &#39;SetupRunContainerId&#39;: &#39;dcid.AutoML_f457e7f2-d002-4f1e-a4cb-d513bcfa753f_setup&#39;,\n  &#39;ProblemInfoJsonString&#39;: &#39;{&#34;dataset_num_categorical&#34;: 0, &#34;is_sparse&#34;: false, &#34;subsampling&#34;: false, &#34;has_extra_col&#34;: true, &#34;dataset_features&#34;: 21}&#39;},\n &#39;outputDatasets&#39;: [],\n &#39;logFiles&#39;: {},\n &#39;submittedBy&#39;: &#39;Gaurav Singh&#39;}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Retrieve the Best Model\n\nUse MLFlow Client to retrieve the spark based model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca387d37-2c6e-4fc2-96ce-e84bbe9b28b5"}}},{"cell_type":"code","source":["import mlflow\nfrom mlflow.tracking import MlflowClient\n\nmlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())\n\n# run_id = run.id\nrun_id = \"AutoML_ef1fd143-53ca-4272-8de9-f9e4cf58f964\"\n\nmlflow_client = MlflowClient()\nmlflow_parent_run = mlflow_client.get_run(run_id)\n\nbest_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\nprint(\"Found best child run id: \", best_child_run_id)\n\nmlflow_best_child_run = mlflow_client.get_run(best_child_run_id)\nmlflow_best_child_run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"631cee36-027c-4bb9-b2b2-3b8ec51e08e8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import os\n\nlocal_dir = \"/tmp/artifact_downloads/{}\".format(mlflow_best_child_run.info.run_id)\nif not os.path.exists(local_dir):\n    os.mkdir(local_dir)\n\nlocal_path = mlflow_client.download_artifacts(mlflow_best_child_run.info.run_id, \"outputs/mlflow_model\", local_dir)\nprint(\"Artifacts downloaded in: {}\".format(local_path))\nprint(\"Artifacts: {}\".format(os.listdir(local_path)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f25c6b5-f864-48ee-a729-742da86d845a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["fitted_model = mlflow.pyfunc.load_model(\"runs:/{}/outputs\".format(mlflow_best_child_run.info.run_id))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"934ba1f0-8136-4c96-864e-85b40d5e5e29"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Print more information about the winning model\nprint(\"Preprocessor: \\n{}\\n\".format(fitted_model.steps[1]))\nprint(\"Estimator: \\n\", fitted_model.steps[2])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79ef1bc3-a28a-494a-975f-5fc722c66ebc"}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python [conda env:devmay] *","language":"python","name":"conda-env-devmay-py"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.10","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"NYC Taxi Tip Predictions - AutoML + Spark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2927027186272135}},"nbformat":4,"nbformat_minor":0}
